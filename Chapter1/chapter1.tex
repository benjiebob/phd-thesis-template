%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Introduction}  %Title of the First Chapter

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


%********************************** %First Section  **************************************
\section{Motivation} %Section - 1.1 

Animal welfare is an important concern for business and society, with an estimated 70 billion animals currently living under human care~\cite{FAOSTAT}. Monitoring and assessment of animal health can be assisted by obtaining accurate measurements
of an individual’s shape, volume and movement. These measurements should
be taken without interfering with the animal’s normal activity, and are needed
around the clock, under a variety of lighting and weather conditions, perhaps at
long range (e.g. in farm fields or wildlife parks). Therefore a very wide range of
cameras and imaging modalities must be handled. For small animals in captivity,
a depth camera might be possible, but techniques which can operate solely from
intensity data will have a much wider range of applicability.

% Between farmyards, research facilities, zoos, animal rescue centres, veterinary centres and sporting centres, over 100 billion animals are currently living under human care \cite{FAOSTAT}. For ethical and financial reasons, these industries often rely on the health and wellbeing of their animal populations and there can be dramatic consequences afforded to organizations deemed to fall short. Pressure groups have been particularly critical of zoos and entertainment industries for their inability to identify and treat behaviour disorders. In some cases, this has necessitated expensive re-homing procedures for animals with late-identified psychosis (commonly stereotypy)~\cite{Guardian-Elephant}. Worse still, some have suggested a link between animal health and welfare and loss of human life~\cite{SWOH-Tilikum}.

% This project is funded by GlaxoSmithKline (GSK), a global pharmaceutical company based in the United Kingdom. In order to sell medications for use in humans, GSK and similar companies have a legal obligation to run controlled clinical trials on animal subjects. For reasons of ethics and promotion of good science, the emphasis on animal welfare is paramount. Strict measures are imposed to minimize any potential animal suffering and to maximize useful data output during the study period. By refining existing methods of behaviour analysis, GSK aim to further reduce the numbers of animals required for testing and support robust conclusions about candidate medications at earlier opportunities. Progress here should assist scientists in identifying medicinal side-effects and promote early attrition of the clinical trial, that is, the process of preventing an unsuitable drug compound from progressing in the R\&D pipeline and thereby reducing any further unnecessary expenditure.

% Within sectors concerned with animal husbandry, there is growing support for a system able to continuously monitor captive animals throughout their entire lifetimes. Due to staff working hours and typically large population sizes, it can be impractical for zookeepers or lab technicians to keep continuous watch over all animals under their care at all times. These issues are particularly acute for nocturnal animals in which symptoms may only become apparent during the night, and `prey' animals that have evolved to deliberately hide pain from perceived predators as a defence mechanism. Rats and mice, the two most common species used in animal research, pose both of these challenges.

%********************************** %Second Section  *************************************
\section{Approach} %Section - 1.2

We address this problem using techniques from the recent human body and
hand tracking literature, combining machine learning and 3D model fitting. A
discriminative front-end uses a deep hourglass network to identify candidate 2D
joint positions. These joint positions are then linked into coherent skeletons by
solving an optimal joint assignment problem, and the resulting skeletons create
an initial estimate for a generative model-fitting back-end to yield detailed shape
and pose for each frame of the video.
Although superficially similar to human tracking, animal tracking (AT) has
some interesting differences that make it worthy of study:

Variability. In one sense, AT is simpler than human tracking as animals generally do not wear clothing. However, variations in surface texture are still
considerable between individuals, and the variety of shape across and within
species is considerably greater. If tracking is specialized to a particular species,
then shape variation is smaller, but training data is even harder to obtain.
Training data. For human tracking, hand labelled sequences of 2D segmentations and joint positions have been collected from a wide variety of sources [3–5].
Of these two classes of labelling, animal segmentation data is available in datasets
such as MSCOCO [4], PASCAL VOC [6] and DAVIS [7]. However this data is
considerably sparser than human data, and must be “shared” across species,
meaning the number of examples for a given animal shape class is considerably
fewer than is available for an equivalent variation in human shape. While segmentation data can be supplied by non-specialist human labellers, it is more
difficult to obtain joint position data. Some joints are easy to label, such as “tip
of snout”, but others such as the analogue of “right elbow” require training of
the operator to correctly identify across species.
Of more concern however, is 3D skeleton data. For humans, motion capture
(mocap) can be used to obtain long sequences of skeleton parameters (joint
positions and angles) from a wide variety of motions and activities. For animal
tracking, this is considerably harder: animals behave differently on treadmills
than in their quotidian environments, and although some animals such as horses
Creatures great and SMAL 3
and dogs have been coaxed into motion capture studios [8], it remains impractical
to consider mocap for a family of tigers at play.
These concerns are of course alleviated if we have access to synthetic training
data. Here, humans and animals share an advantage in the availability of parameterized 3D models of shape and pose. The recent publication of the Skinned
Multi-Animal Linear (SMAL) model [9] can generate a wide range of quadruped
species, although without surface texture maps. However, as with humans, it
remains difficult to generate RGB images which are sufficiently realistic to train
modern machine learning models. In the case of humans, this has been overcome
by generating depth maps, but this then requires a depth camera at test time [10].
The alternative, used in this work, is to generate 2D silhouette images so that
machine learning will predict joint heatmaps from silhouettes only

\section{Background} %Section - 1.1 

    \subsection{Existing solutions}
    At present, a number of animal monitoring systems exist specifically for use in clinical work. Some are `invasive', meaning they require animals to undergo a surgical operation (generally to implant a tracking chip) before monitoring can take place. The general aim of such systems is to obtain accurate telemetry information (such as blood pressure, ECG etc.) over 3D tracking. By constrast, this research aims to develop a non-invasive system in order to reduce stress to the animals and costs associated with the surgery.

    Given the benefit that even a crude tracking system can have in ensuring some basic health standards (e.g.\ to check that \emph{some} activity occurs over a given time period), some systems further attempt to monitor the animals' physical activity. The most basic of these comprise simple movement detection, to establish energy and inquisitiveness levels of the target animals. Most systems achieve this by either placing floor-level pressure pads~\cite{zammit2010reliability}, or by installing an overhead camera which performs simple visual blob detection via colour thresholding~\cite{tort2006simple}, \cite{rodriquez2017toxtrac}. One such open source system instructs the user to set a colour tolerance that masks all non-animal pixels and provide expected maximum and minimum animal sizes (in pixels) to help eliminate noise. While this is effective at tracking multiple animals with distinctive colour when placed in an arena with a solid, fixed background, it does not work well in many scenarios, e.g.\ outdoors. The presence of changing light levels, casting of shadows across tracking targets or moving backgrounds (e.g.\ foliage) make such thresholds ineffective. Further, this system's ability to distinguish between multiple tracked subjects is hindered when animals cross one another, as two individual blobs temporarily become one, and from then on are difficult to resolve.

    Some work has been done in automatic behavioural scoring for rodents, in which up to ten predefined behaviours can be visually recognized. However, all approaches identified are built on top of a thresholding segmentation algorithm and none readily extend to other animal species. Vium's Digital Vivaria~\cite{vium_inc} are also notable, as apart from their range of in-cage sensors to track environmental statistics, they are also able to determine animal breathing rate by analysing image pixels which change within a particular frequency range. They further claim to be able to identify the signs of animal arthritis, however no description of this algorithm exists in the public domain. Unfortunately, Vium's system is not able to distinguish between multi-housed animals and again, does not extend to non-rodent anatomies. At present, no system is known that can accurately detect behaviour, even across common quadrupeds (such as horses, dogs, pigs etc.).

    \subsection{Project objectives}
    This project aims to benefit this space by developing a state-of-the art tracking system to enable recovery of a per-frame 3D animal reconstruction from a live video stream. The system should apply to a wide range of animal species without significant customization. Success in this endeavour would enable real-time changes of a known skeletal structure to be programmatically analysed to completely model an animal’s movements. These behaviour patterns could then be interpreted to form a profile for each animal in a batch, taking into account expected norms for their species as well as their individual personality traits. When animals are first brought into a facility, they are given some time to acclimatize to their new surroundings before a clinical study begins. The application could make use of this period to refine behaviour models to their particular characteristics without being influenced by external factors. The system would then begin monitoring the population, storing detailed analytics and reacting to any deviations to an animal’s unique behaviour profile. As a simple example, should a typically lively and sociable dog suddenly begin exhibiting signs of withdrawal from the group, this would indicate a cause for concern and be stored in that animal’s ‘virtual log book’. In some cases, an animal may begin to exhibit signals that demand immediate attention, such as a dramatic and sudden energy drop that may indicate pain. The application could handle such events by sending an SMS text message to an on-call veterinary professional, to alert them of the specific problem and thereby enable a rapid response. These real-time diagnostics could then be aggregated and displayed on a dashboard screen, visible to all laboratory technicians. A concept drawing is shown in Figure \ref{fig:wellness_dashboard}.

    \begin{figure}[H] % Example image
        \center{\includegraphics[width=0.95\linewidth]{dash}}
        \caption{Concept drawing showing an animal health dashboard. Specific wellness markers WI1,...,WI6 have yet to be determined.}
        \label{fig:wellness_dashboard}
    \end{figure}

    % Define the problem of 3D reconstruction using a template mesh
    % Explain that it allows 
    \section{Problem definition}
    A major challenge of this work is to develop and adapt methods for resolving the inherent ambiguity associated with recovering a 3D model from 2D input data. This challenge can be overcome by augmenting the input video sequence (Figure \ref{fig:arap_input}) with strong prior knowledge about the target species class (e.g.\ quadruped body measurements). This prior knowledge can be divided into two components: a \emph{shape} prior that enforces topological (e.g.\ order of body parts) and measurement constraints (e.g.\ length of limbs), and a \emph{pose} prior that defines likely limb configurations and can be used to rule out those which are anatomically impossible.

    \begin{figure}[H]
        \centering
        \begin{subfigure}{0.33\textwidth}
        \centering
            \includegraphics[width=1\linewidth]{input/66}
        \end{subfigure}%
        \begin{subfigure}{0.33\textwidth}
        \centering
            \includegraphics[width=1\linewidth]{input/167}
        \end{subfigure}%
        \begin{subfigure}{0.33\textwidth}
        \centering
            \includegraphics[width=1\linewidth]{input/208}
        \end{subfigure}%
        \caption{An example input video sequence.}
        \label{fig:arap_input}
    \end{figure}

    An example output showing the recovery of a 3D model from an input 2D monocular video is shown in Figure \ref{fig:intro_arap_output}:
    
    \begin{figure}[H]
        \centering
        \begin{subfigure}{1\textwidth}
        \centering
            \includegraphics[width=1\linewidth]{input/arapsfm_output}
        \end{subfigure}%
        \caption{Sample output printed from Deformable Mesh Animation~\cite{arap_stebbing}.}
        \label{fig:intro_arap_output}
    \end{figure}
    
    A distinction should be made between two common tracking techniques: (1) discriminative body part recognizers and joint position predictors, and (2) 3D reconstructions via generative model fitting. Discriminative predictors have become the dominant paradigm in human body tracking to facilitate common use-cases, such as gesture detection or controllerless gameplay. However, recovering 3D models from human subjects is a growing field. Applications are found in fashion to faciliate online `try-ons' for virtual clothing~\cite{lin2014digital}, in animation and visual effects to generate virtual characters from live actor performances~\cite{laine2017production}, and in healthcare for tracking patients' body weight over time~\cite{velardo2010weight}. It is hypothesized that recovering a full 3D animal reconstruction is necessary to enable the intended diagnostic purposes of this animal work. In particular, returning only joint positions or body parts may be insufficient to estimate animal weight. If this can be realized, identifying behavioural changes from the reconstruction is expected to be a relatively straightforward machine learning problem. 

    A typical method for recovering 3D structure from tracking targets is using a \emph{model fitting} approach, in which a 3D object representative of the target class is adapted to recreate the performance of the target. This method involves: (1) parameterizing a representative 3D \emph{template mesh} with terms that represent shape and pose attributes and (2) defining an optimizer to adapt to these per-frame parameter settings to an input video sequence. An example of a template mesh is shown in Figure~\ref{fig:arap_template}.
    
    \begin{figure}[H] % Example image
        \center{\includegraphics[width=0.2\linewidth]{template_mesh}}
        \caption{An example prior, in this case a template mesh.}
        \label{fig:arap_template}
    \end{figure}

    Shape attributes capture variation between different members of the target class and remain constant for a particular individual. For example, shape parameters may be adapted to vary a model's height and weight. However, pose attributes generally capture limb positions and joint angles, and therefore tend to vary considerably during a capture sequence. Figure~\ref{fig:black_shape} highlights the difference by keeping pose parameters fixed while shape attributes are varied between the three models~\cite{Streuber:SIGGRAPH:2016}.

    \begin{figure}[H] % Example image
        \center{\includegraphics[width=0.9\linewidth]{body_shapes}}
        \caption{Varying human shape parameters while pose remains fixed. Reprinted from~\cite{Streuber:SIGGRAPH:2016}.}
        \label{fig:black_shape}
    \end{figure}
    
    Shape and pose parameters derived from a video sequence can be applied to the template mesh to generate a digital version of the same activity. If successful, the changing parameters should appear to adapt (or morph) the template mesh to faithfully reconstruct the performance given by the original live animal. In early experimentation, in which tracking targets are restricted to the same species, the template can be chosen to be a close shape fit to the target animal, thereby largely reducing the problem to finding optimal per-frame pose parameters. However, tracking examples are eventually broadened to include a wide range of animal species.

%********************************** % Third Section  *************************************
\section{Contributions}  %Section - 1.3 
In summary, the contributions of this thesis are as follows:
\begin{enumerate}
    \item We demonstrate a robust framework for 3D animal reconstruction using deformable template models
\end{enumerate}

\section{Co-Authored Papers}  %Section - 1.4

Extracts from this thesis appear in the following co-authored publications and preprints. Chapter 4 contains work from:

\begin{enumerate}
    \item Benjamin Biggs, Thomas Roddick, Andrew Fitzgibbon and Roberto Cipolla, Creatures Great and SMAL, ACCV 2018 ORAL Presentation
\end{enumerate}

Chapter 5 contains work from:

\begin{enumerate}
    \item Benjamin Biggs, Oliver Boyne, James Charles, Andrew Fitzgibbon and Roberto Cipolla, Who Left the Dogs Out? 3D Animal Reconstruction with Expectation Maximization In the Loop, ECCV 2020
\end{enumerate}

And Chapter 6 contains work from:

\begin{enumerate}
    \item Benjamin Biggs, Sebastien Ehrhadt, Hanbyul Joo, Benjamin Graham, Andrea Vedaldi and David Novotny, 3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data, NeurIPS 2020 SPOTLIGHT Presentation
\end{enumerate}

\section{Thesis Structure}  %Section - 1.3 

The following five thesis chapters discuss methods for deriving 3D animal reconstructions from monocular input images and video. The first two chapters cover necessary background and an in-depth literature review covering related methods for animal reconstruction. Chapter 4 discusses an approach for animal reconstruction by learning only from synthetic training data. Chapter 5 describes an end-to-end and real-time technique applied to the challenging dog category. Chapter 6 introduces a method for handling input images with significant ambiguity. The final Chapter 7 summarizes the work and offers some opportunities for future endeavours in the field.