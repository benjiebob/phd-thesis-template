%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Related Work}

\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

\section{Introduction}

This chapter discusses background and methods related to 3D shape and pose estimation for articulated subjects. We begin with techniques for correspondence prediction -- a classical method which discusses work focussing on 3D shape and pose estimation for animals. 3D shape and pose estimation for articulated subjects -- primarily animals and humans. We initially focus on skeletal prediction techniques, which output either sets 2D or 3D keypoints. Such techniques are of value to our objective of 3D surface reconstruction, as have been employed in multi-stage pipelines where keypoints are predicted first before a subsequent model fitting stage. The chapter continues with an evaluation of so-called `model-free' techniques, which operate without an explicit template prior.

% Skeletal prediction methods

% Is it a multi-stage approach?
% Does it have a prior?
% 

% Kinect Paper | 

% \section{Point correspondences}
% \section{3D Deformable Model of People and Animals}
% \section{Methods for Single-view Reconstruction}

\input{Chapter3/point-corres.tex}
\input{Chapter3/seg-obj-det.tex}
% \input{Chapter3/3d-skel.tex}
\input{Chapter3/modelling-articulated.tex}
\input{Chapter3/model-based-reco.tex}
% \input{Chapter3/model-free-reco.tex}
\input{Chapter3/lit-review-tbl.tex}


% https://arxiv.org/pdf/1903.00812.pdf



% large dataset on large large Techniques in this section typically achieve this using data-driven machine learning algorithms, which can be trained on various  general, data-driven machine learning algorithms are used to predict an association between image pixels and locations with a semantic meaning. techniques used to achieve this techniques achieve this In general, data driven machine learning techniques are used to train an algorithm to associate image appearance features with semantically-meaningful partsIn order to teach a system to understand semantic this section, we will discuss techniques for predicting keypoints from a pre-defined list

% These approaches do offer some advantages; in particular, the approaches do not require a training procedure based on a labelled dataset, although the techniques cannot be used to associate image points to a representative 3D mesh. In this section, we will discuss techniques for predicting points from a pre-defined list 

% a labelled dataset this does offer some advantages (particularly that the approaches do not require a labelled dataset for training, data 

% and in general, the number of correspondences the number of detected correspondences can differ between test examples and there is no pre-determined there is no pre-determined list of detected correspondences points the methods should obtain, and in general the number of returned keypoints can differ  used for identifying 2D image points based on a pre-defined   approach to identifying image points, although this time the desired locations will are pre-defined.

% \begin{enumerate}
%     \item Talk about all 2D keypoint detection techniques
%     \item Talk about 
% \end{enumerate}

% For example, For example, techniques such as SIFT generate different feature descriptions for two points taken on different zebras, due to the different patterns. Such systems also struggle greatly under object-viewpoint, particularly for 

% which relies on local gradient information will generate different feature descriptions for two points taken on different zebra since the patterns may differ. The next class of techniques are designed to overcome this limitation, and offer matching based on \emph{semantic point correspondences}.




% unfortunately, these techniques 

% such as to ensure uniqueness ensure specificity and comparing feature descriptors computed from them. Early feature descriptors focus only Feature descriptors often capture local statistics related to the image location and aim to have some invariance to different lighting conditions, scales, rotations or other transforms. from which  (typically repeatible features such as edges Techniques fall into two categories: global image descriptors are calculated on the whole image, and have some advantages in that they are invariant to matching based on the whole image, and have some advantages since they are naturall invariant to invarient 

% majority of techniques solve matching based on local image-features, techniques match based on local features, i.e. rely on general, techniques are used to identify so-called \emph{interest points} which have some repeatibility properties for which a \emph{feature descriptor} can be Historically, the most successful methods operate by Early techniques designed for stereo matching and for optical flow were designed to operate under small viewpoint changes, but early technique proved suitable for stereo matching under small viewpoint changes, but was not rotation invariant and for deriving point correspondences since the 1980s, echniques for deriving point correspondences between images has existed since the 1980soperated on image pixel intensity values, without much consideration for the underlying objects. Improvements were made with geometric techniques, such as edge and corner detectors, which offered some robustness to varying lighting conditions. However, the mid-level features represenations of SIFT~\cite{}, HOG~\cite{}, DAISY~\cite{}, VLAD~\cite{} etc. offered considerable improvements, allowing point matching under various object scales and camera viewpoints.

% However, while suitable for processing such techniques were unfortunately unable to match semantically-meaningful keypoint locations across different object instances

% the feature representations of techniques struggle with varying camera viewpoints, still typically fail when 

% at some robustness to that related mid-level appearance features, such as corners 

% Major imawithout consideration for the objects they purely on image pixels, with little knowledge of the objects they Of course, determine which 2D image locations are in correspondence 

% The history of deriving point correspondences begins with stereo and optical flow, which use 

% Even the earliest reconstruction techniques, such as in stereo or optical flow based methods, rely on point correspondences to determine 3D structure. 

% to use of point correspondences to 


% For example, imagine we have captured multiple images ${I_1, I_2, ...}$ of the same static scene containing a dog. A classical approach for recovering the 3D 3D dog For example, imagine we have various images captured of the same static scene containing a dog. In order to determine the consider a real-world point on the end of a dog's nose for which we have yet to determine the true 3D world location. To recover the 3D point, we may start by grouping together projections of this point $\{(u_i, v_i)\} \in R^2$ in various images we have captured of the scene. From these point correspondences, we could begin 


% we may start We may start by grouping together various projections of this point in various images we have captured of the scene From various images captured of the scene, we may start by grouping together the various projections of this nose point it is useful to group together the various projections of this point . Further, we can various projections of this point in on the end of a dogs nose, scene containing a dog, we can group to group 2D image points 

% points a scene containing a dog, we may wish to group , whether in related locations between two images, an image and a 3D surface or two 3D surfaces. Often, point correspondences are used to group together multiple image views of the same real-world location, or to relate an image point with a location on a representative 3D surface. 


% Throughout the long history of 3D reconstruction, nearly all methods which focus on recovering complex 3D objects from 2D image data make use of \emph{point correspondences} to constrain the problem. By understanding which pairs of Early work focuses on \emph{image matching} to 


% In order to reconstruct a complex 3D object from 2D image data, we typically require significant constraints from Techniques which reconstruct complex 3D subjects from 2D image data typically require 

% In order to reconstruct a complex 3D subject from 2D image data, it is almost always essential to constrain  3D articulated subject from 2D image data, it is almost always image, it is alms3D reconstruction has a long history 3D reconstruction techniques have a long history in reconstruction, and nearly all require as 

% \begin{enumerate}
%     \item 3D reconstruction techniques rely upon point correspondences. This has a very long history:
%     \item Optical flow, mid-level discriptors (SIFT, DAISY etc.)
%     \item More recently, pose estimation techniques have found themselves useful 
% \end{enumerate}




% \section{Obtaining animal test data}
%     A significant drawback due to the lack of available training data is that state-of-the-art segmentation pipelines require a wealth of (RGB Input, Segmentation) and (IR Input, Segmentation training pairs which are not readily available for animal targets. To resolve this, a collaborative project is underway between GSK and Texuna to design a bespoke camera module which can be fit into rodent, dog, mini-pig and rabbit enclosures. Figure \ref{fig:texuna_cage} shows a recent prototype design. The cameras are able to flip between RGB and IR capture modes and use IP camera technology, which is supported by a number of off-the-shelf recording systems. Once animal data is successfully recorded, it will be passed to human annotators to create a suitable dataset to train a segmentation network. Until this has been obtained, the system is designed on the premise of receiving perfect silhouette segmentations. 

%     % Talk a little more about the data -- problems (all outside?), occlusions, pets, number of pictures per animal (distribution) 
%     For testing, there are examples of real-world animal segmentations that form a satisfactory set for system testing. Between the Weizmann Horse Dataset~\cite{weizmann}, the IIIT-OXFORD PET dataset~\cite{oxfordpetdata} and animal superclasses from popular datasets such as MS Coco~\cite{lin2014microsoft} and PASCAL VOC~\cite{everingham2010pascal}, there are approximately one thousand RGB-segmentation pairs for independent images (i.e.\ not part of an available video sequence). It is worth noting that the distribution of images is heavily weighted towards cats, dogs and horses over other animal species. Moreover, images tend to be taken in outdoor environments with side-on animal views. This bias has been partially resolved by sourcing an additional 1500 frames from YouTube and the BBC Blue Planet II documentary series\footnote{Appropriate permissions have been sought where applicable}. These sequences were all segmented by hand, using the RotoBrush tool provided by the Adobe After-Effects~\cite{Bai:2009:VSC} package.  









