% Encoding: UTF-8

@InProceedings{rupprecht17learning,
  author = {Rupprecht, Christian and Laina, Iro and DiPietro, Robert and Baust, Maximilian and Tombari, Federico and Navab, Nassir and Hager, Gregory D.},
  title = {Learning in an Uncertain World: Representing Ambiguity Through Multiple Hypotheses},
  booktitle =iccv,
  year = {2017}
}

@article{lloyd1982least,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@article{gray1998quantization,
  title={Quantization},
  author={Gray, Robert M. and Neuhoff, David L.},
  journal={IEEE transactions on information theory},
  volume={44},
  number={6},
  pages={2325--2383},
  year={1998},
  publisher={IEEE}
}

@inproceedings{vonmarcard2018recovering,
  title = {Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera},
  author = {von Marcard, Timo and Henschel, Roberto and Black, Michael and Rosenhahn, Bodo and Pons-Moll, Gerard},
  booktitle = eccv,
  year = {2018},
  month = {sep}
}

@article{cao2018openpose,
  author={Z. {Cao} and G. {Hidalgo} and T. {Simon} and S. -E. {Wei} and Y. {Sheikh}},
  journal=pami, 
  title={OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields}, 
  year={2019},
  volume={43},
  number={1},
  pages={172-186},
  doi={10.1109/TPAMI.2019.2929257}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle=eccv,
  year={2014},
}

@InProceedings{akhter15pose-conditioned,
  author    = {I. Akhter and M. J. Black},
  booktitle = cvpr,
  title     = {Pose-Conditioned Joint Angle Limits for {3D} Human Pose Reconstruction},
  year      = {2015},
}

@inproceedings{sorkine2007rigid,
  title={As-rigid-as-possible surface modeling},
  author={Sorkine, Olga and Alexa, Marc},
  booktitle={Symposium on Geometry processing},
  volume={4},
  year={2007}
}

@Manual{unity2017,
  title = {Unity Manual},
  author = {{Unity Technologies}},
  organization = {Unity Technologies},
  address = {San Francisco, CA 94103},
  year = {2015},
  url = {http://docs.unity3d.com/Manual/index.html},
}

@misc{davinci,
  title = {The Vitruvian Man},
  author = {{Leonardo da Vinci}},
  year = {c. 1487}
}

@inproceedings{taylor2012vitruvian,
  title={The vitruvian manifold: Inferring dense correspondences for one-shot human pose estimation},
  author={Taylor, Jonathan and Shotton, Jamie and Sharp, Toby and Fitzgibbon, Andrew},
  booktitle=cvpr,
  pages={103--110},
  year={2012},
  organization={IEEE}
}

@article{barron2001estimating,
  title={Estimating anthropometry and pose from a single uncalibrated image},
  author={Barr{\'o}n, Carlos and Kakadiaris, Ioannis A},
  journal={Computer Vision and Image Understanding},
  volume={81},
  number={3},
  pages={269--284},
  year={2001},
  publisher={Elsevier}
}

@inproceedings{kinect_fusion,
  title={{KinectFusion}: Real-time dense surface mapping and tracking},
  author={Newcombe, Richard A and Izadi, Shahram and Hilliges, Otmar and Molyneaux, David and Kim, David and Davison, Andrew J and Kohi, Pushmeet and Shotton, Jamie and Hodges, Steve and Fitzgibbon, Andrew},
  booktitle={Mixed and augmented reality (ISMAR), 2011 10th IEEE international symposium on},
  pages={127--136},
  year={2011},
  organization={IEEE}
}

@article{kinectpaper,
  title={Real-time human pose recognition in parts from single depth images},
  author={Shotton, Jamie and Sharp, Toby and Kipman, Alex and Fitzgibbon, Andrew and Finocchio, Mark and Blake, Andrew and Cook, Mat and Moore, Richard},
  journal={Communications of the ACM},
  volume={56},
  number={1},
  pages={116--124},
  year={2013},
  publisher={ACM}
}

@inproceedings{pishchulin2016deepcut,
  title={{DeepCut}: Joint subset partition and labeling for multi person pose estimation},
  author={Pishchulin, Leonid and Insafutdinov, Eldar and Tang, Siyu and Andres, Bjoern and Andriluka, Mykhaylo and Gehler, Peter V and Schiele, Bernt},
  booktitle=cvpr,
  pages={4929--4937},
  year={2016}
}

% Mesh definition
@phdthesis{smith2006vertex,
  author = {Smith, Colin},
  title = {On Vertex-vertex Systems and Their Use in Geometric and Biological Modelling},
  year = {2006},
  isbn = {978-0-494-19574-1},
  note = {AAINR19574},
  publisher = {University of Calgary},
  school = {University of Calgary},
  address = {Calgary, Alta., Canada, Canada},
} 

@inproceedings{toshev2014deeppose,
  title={{DeepPose}: Human pose estimation via deep neural networks},
  author={Toshev, Alexander and Szegedy, Christian},
  booktitle=cvpr,
  pages={1653--1660},
  year={2014}
}

@Manual{blender2017,
   title = {Blender - a 3D modelling and rendering package},
   author = {{Blender Online Community}},
   organization = {Blender Foundation},
   address = {Blender Institute, Amsterdam},
   year = {2017},
   url = {http://www.blender.org},
 }

@techreport{robinette2002civilian,
  title={{Civilian American and European Surface Anthropometry Resource (CAESAR), Final Report. Volume 1. Summary}},
  author={Robinette, Kathleen M and Blackwell, Sherri and Daanen, Hein and Boehmer, Mark and Fleming, Scott},
  year={2002},
  institution={SYTRONICS INC DAYTON OH}
}

@article{taylor2016efficient,
  title={Efficient and precise interactive hand tracking through joint, continuous optimization of pose and correspondences},
  author={Taylor, Jonathan and Bordeaux, Lucas and Cashman, Thomas and Corish, Bob and Keskin, Cem and Sharp, Toby and Soto, Eduardo and Sweeney, David and Valentin, Julien and Luff, Benjamin and others},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={143},
  year={2016},
  publisher={ACM}
}

@inproceedings{tekin2016direct,
  title={Direct prediction of 3d body poses from motion compensated sequences},
  author={Tekin, Bugra and Rozantsev, Artem and Lepetit, Vincent and Fua, Pascal},
  booktitle=cvpr,
  pages={991--1000},
  year={2016}
}

@misc{rendering,
  author  = {{Wikimedia Commons}},
  title   = "Ray trace diagram",
  year    = "2007",
  urlseen = "07-01-18",
  url     = "https://commons.wikimedia.org/w/index.php?curid=3869326",
}

@misc{polygon_mesh,
  author  = {{Wikimedia Commons}},
  title   = "Dolphin triangle mesh",
  year    = "2007",
  urlseen = "12-01-18",
  url     = "https://commons.wikimedia.org/wiki/File:Dolphin_triangle_mesh.png#",
}


@inproceedings{kavan2007skinning,
  title={Skinning with dual quaternions},
  author={Kavan, Ladislav and Collins, Steven and {\v{Z}}{\'a}ra, Ji{\v{r}}{\'\i} and O'Sullivan, Carol},
  booktitle={Proceedings of the 2007 symposium on Interactive 3D graphics and games},
  pages={39--46},
  year={2007},
  organization={ACM}
}

@inproceedings{sharma19monocular,
	Author = {Saurabh Sharma and Pavan Teja Varigonda and Prashast Bindal and Abhishek Sharma and Arjun Jain},
	Booktitle = iccv,
	Title = {Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking},
	Year = {2019}}

@inproceedings{li19generating,
	Author = {C. Li and G. Hee Lee},
	Booktitle = cvpr,
	Title = {Generating Multiple Hypotheses for 3D Human Pose Estimation with Mixture Density Network},
	Year = {2019}}

@techreport{bishop94mixture,
	Author = {C. M. Bishop},
	Institution = {Aston University},
	Title = {Mixture Density Networks},
	Year = {1994}}

@InProceedings{guler2018densepose,
  author    = {G{\"u}ler, R{\i}za Alp and Neverova, Natalia and Kokkinos, Iasonas},
  booktitle = cvpr,
  title     = {Densepose: Dense human pose estimation in the wild},
  year      = {2018},
  pages     = {7297--7306},
}

@incollection{sohn2015cvae,
	title = {Learning Structured Output Representation using Deep Conditional Generative Models},
	author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	booktitle = nips,
	year = {2015},
}


@inproceedings{cheng19occlusion-aware,
	Author = {Y. Cheng and B. Yang and B. Wang and W. Yan and R. T. Tan},
	Booktitle = iccv,
	Title = {Occlusion-Aware Networks for 3D Human Pose Estimation in Video},
	Year = {2019}}



@inproceedings{guzman2012multiple,
  title={Multiple choice learning: Learning to produce multiple structured outputs},
  author={Guzman-Rivera, Abner and Batra, Dhruv and Kohli, Pushmeet},
  booktitle=nips,
  pages={1799--1807},
  year={2012}
}

@Article{ionescu2013human3,
  author    = {Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal   = pami,
  title     = {Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
  year      = {2014},
  month     = {jul},
  number    = {7},
  pages     = {1325-1339},
  volume    = {36},
  publisher = {IEEE Computer Society},
}

@inproceedings{IonescuSminchisescu11,
    author = {Catalin Ionescu, Fuxin Li, Cristian Sminchisescu},
    title = {Latent Structured Models for Human Pose Estimation},
    booktitle = iccv,
    year = {2011}
}

@inproceedings{varol18bodynet,
	Author = {G. Varol and D. Ceylan and B. Russel and J. Yang and E. Yumer and I. Laptev and C. Schmid},
	Booktitle = eccv,
	Title = {{BodyNet}: Volumetric inference of {3D} human body shapes},
	Year = {2018}}

@inproceedings{pavlakos18learning,
	Author = {Georgios Pavlakos and Luyang Zhu and Xiaowei Zhou and Kostas Daniilidis},
	Booktitle = cvpr,
	Title = {Learning to estimate {3D} human pose and shape from a single color image},
	Year = {2018}}

@InProceedings{omran18neural,
  author        = {Mohamed Omran and Christoph Lassner and Gerard Pons-Moll and Peter V. Gehle and Bernt Schiele},
  booktitle     = threedv,
  title         = {Neural body fitting: Unifying deep learning and model based human pose and shape estimation},
  year          = {2018},
  date-added    = {2019-11-08 00:37:52 +0000},
  date-modified = {2019-11-08 00:37:52 +0000},
}

@InProceedings{tung17self-supervised,
  author        = {Hsiao-Yu Fish Tung and Hsiao-Wei Tung and Ersin Yumer and Katerina Fragkiadaki},
  booktitle     = nips,
  title         = {Self-supervised learning of motion capture},
  year          = {2017},
  date-added    = {2019-11-08 00:37:52 +0000},
  date-modified = {2019-11-08 00:37:52 +0000},
}

@Article{loper15smpl,
  author        = {M. Loper and N. Mahmood and J. Romero and G. Pons-Moll and M. J. Black and},
  journal       = {{ACM} Trans. on Graphics},
  title         = {{SMPL}: A skinned multi- person linear model},
  year          = {2015},
  date-added    = {2019-11-08 00:25:22 +0000},
  date-modified = {2019-11-08 00:25:22 +0000},
}

@InProceedings{huang17towards,
  author    = {Yinghao Huang and Federica Bogo and Christoph Lassner and Angjoo Kanazawa and Peter V. Gehler and Javier Romero and Ijaz Akhter and Michael J. Black},
  booktitle = threedv,
  title     = {Towards accurate marker-less human shape and pose estimation over time},
  year      = {2017},
}

@inproceedings{lassner17unite,
	Author = {Christoph Lassner and Javier Romero and Martin Kiefel and Federica Bogo and Michael J. Black and Peter V. Gehler},
	Booktitle = cvpr,
	Title = {Unite the people: Closing the loop between {3D} and {2D} human representations},
	Year = {2017}}

@inproceedings{xiang19monocular,
	Author = {Donglai Xiang and Hanbyul Joo and Yaser Sheikh},
	Booktitle = cvpr,
	Title = {Monocular total capture: Posing face, body, and hands in the wild.},
	Year = {2019}}

@inproceedings{pavlakos19expressive,
	Author = {Georgios Pavlakos and Vasileios Choutas and Nima Ghorbani and Timo Bolkart and Ahmed A. A. Osman and Dimitrios Tzionas and Michael J. Black},
	Booktitle = cvpr,
	Title = {Expressive body capture: {3D} hands, face, and body from a single image},
	Year = {2019}}

@inproceedings{joo18total,
	Author = {Hanbyul Joo and Tomas Simon and Yaser Sheikh},
	Booktitle = cvpr,
	Title = {Total capture: A {3D} deformation model for tracking faces, hands, and bodies},
	Year = {2018}}

@inproceedings{zanfir18monocular,
	Author = {A. Zanfir and E. Marinoiu and C. Sminchisescu},
	Booktitle = cvpr,
	Title = {Monocular {3D} pose and shape estimation of multiple people in natural scenes --- The importance of multiple scene constraints},
	Year = {2018}}

@inproceedings{bogo16keep,
	Author = {F. Bogo and A. Kanazawa and C. Lassner and P. Gehler and J. Romero and M. J. Black},
	Booktitle = eccv,
	Title = {Keep it {SMPL}: Automatic estimation of {3D} human pose and shape from a single image},
	Year = {2016}}

@InCollection{sigal08combined,
  author    = {Sigal, Leonid and Alexandru Balan and Michael J. Black},
  booktitle = nips,
  title     = {Combined discriminative and generative articulated pose and non-rigid shape estimation},
  year      = {2008},
}

@inproceedings{guan09estimating,
	Author = {P. Guan and A. Weiss and A. O. Balan and M. J. Black},
	Booktitle = iccv,
	Title = {Estimating human shape and pose from a single image},
	Year = {2009}}

@inproceedings{anguelov05scape,
	Author = {D. Anguelov and P. Srinivasan and D. Koller and S. Thrun and J. Rodgers and J. Davis},
	Booktitle = {{ACM} Trans. on Graphics},
	Title = {{SCAPE}: shape completion and animation of people},
	Year = {2005}}

@InProceedings{zanfir18deep,
  author    = {A. Zanfir and E. Marinoiu and M. Zanfir and A.-I. Popa and C. Sminchisescu},
  booktitle = nips,
  title     = {Deep network for the integrated {3D} sensing of multiple people in natural images},
  year      = {2018},
}

@inproceedings{tan17indirect,
	Author = {V. Tan and I. Budvytis and R. Cipolla},
	Booktitle = bmvc,
	Title = {Indirect deep structured learning for {3D} human body shape and pose prediction},
	Year = {2017}}

@inproceedings{sun18integral,
	Author = {X. Sun and B. Xiao And F. Wei and S. Liang and Y. Wei},
	Booktitle = eccv,
	Title = {Integral Human Pose Regression},
	Year = {2018}}

@InProceedings{sun2019deep,
  author = {Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
  title = {Deep High-Resolution Representation Learning for Human Pose Estimation},
  booktitle = {CVPR 2019},
  year = {2019},
  month = {June},
  abstract = {In this paper, we are interested in the human pose estimation problem with a focus on learning reliable highresolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first
  stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutliresolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich highresolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.},
  url = {https://www.microsoft.com/en-us/research/publication/deep-high-resolution-representation-learning-for-human-pose-estimation/},
}

@Article{rogez18lcr-net,
  author  = {Gr{\'{e}}gory Rogez and Philippe Weinzaepfel and Cordelia Schmid},
  journal = pami,
  title   = {{LCR-Net++}: Multi-person {2D} and {3D} Pose Detection in Natural Images},
  year    = {2018},
}

@inproceedings{mehta17vnect,
	Author = {Mehta, Dushyant and Sridhar, Srinath and Sotnychenko, Oleksandr and Rhodin, Helge and Shafiei, Mohammad and Seidel, Hans-Peter and Xu, Weipeng and Casas, Dan and Theobalt, Christian},
	Booktitle = siggraph,
	Title = {{VNect}: Real-time 3D Human Pose Estimation with a Single {RGB} Camera},
	Year = {2017}}

@inproceedings{martinez17a-simple,
	Author = {J. Martinez and J. Romero and M. Kiefel and F. Bogo and M. J. Black and P. V. Gehler},
	Booktitle = cvpr,
	Title = {A simple yet effective baseline for {3D} human pose estimation},
	Year = {2017}}


@inproceedings{dinh17density,
	Author = {L. Dinh and J. Sohl-Dickstein and S. Bengio},
	Booktitle = iclr,
	Title = {Density estimation using {Real NVP}},
	Year = {2017}}

@inproceedings{kolotouros19learning,
	Author = {Nikos Kolotouros and Georgios Pavlakos and Michael J. Black and Kostas Daniilidis},
	Booktitle = iccv,
	Title = {Learning to Reconstruct {3D} Human Pose and Shape via Model-fitting in the Loop},
	Year = {2019}
	}

@inproceedings{kolotouros19convolutional,
	Author = {Nikos Kolotouros and Georgios Pavlakos and Kostas Daniilidis},
	Booktitle = cvpr,
	Title = {Convolutional Mesh Regression for Single-Image Human Shape Reconstruction},
	Year = {2019}
	}

@inproceedings{kanazawa18end-to-end,
	Author = {Angjoo Kanazawa and Michael J. Black and David W. Jacobs and Jitendra Malik},
	Booktitle = cvpr,
	Title = {End-to-end Recovery of Human Shape and Pose},
	Year = {2018}}

@inproceedings{wu16learning,
	Author = {J. Wu and C. Zhang and T. Xue and W. T. Freeman and J. B. Tenenbaum},
	Booktitle = nips,
	Title = {Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling},
	Year = {2016}}

@inproceedings{gadelha163d-shape,
  Author = {Matheus Gadelha and Subhransu Maji and Rui Wang},
  Booktitle = threedv,
  Title = {{3D} Shape Induction from {2D} Views of Multiple Objects},
  Year = {2017}
}

@article{henderson19learning,
  Author = {P. Henderson and V. Ferrari},
  journal = {International Journal of Computer Vision},
  Title = {Learning single-image {3D} reconstruction by generative modelling of shape, pose and shading},
  Year = {2019}
}

@inproceedings{henzler19escaping,
	Author = {Henzler, Philipp and Mitra, Niloy and Ritschel, Tobias},
	Booktitle = iccv,
	Title = {Escaping Plato's Cave using Adversarial Training: 3D Shape From Unstructured 2D Image Collections},
	Year = {2019}}

@inproceedings{gerig18morphable,
	Author = {T. Gerig and A. Morel-Forster and C. Blumer and B. Egger and M. L{\"u}thi and S. Sch{\"o}nborn and T. Vetter},
	Booktitle = {Proc. Automatic Face \& Gesture Recognition},
	Title = {Morphable Face Models - An Open Framework},
	Year = {2018}}

@inproceedings{paysan09a-3d-face,
	Author = {P. Paysan and R. Knothe and B. Amberg and S. Romdhani and T. Vetter},
	Booktitle = {Advanced video and signal based surveillance},
	Title = {A {3D} Face Model for Pose and Illumination Invariant Face Recognition},
	Year = {2009}
}

@inproceedings{achlioptas17learning,
  title = 	 {Learning Representations and Generative Models for 3{D} Point Clouds},
  author =       {Achlioptas, Panos and Diamanti, Olga and Mitliagkas, Ioannis and Guibas, Leonidas},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {40--49},
  year = 	 {2018},
  editor = 	 {Jennifer Dy and Andreas Krause},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/achlioptas18a/achlioptas18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/achlioptas18a.html},
}

@inproceedings{newell2016stacked,
  title={Stacked hourglass networks for human pose estimation},
  author={Newell, Alejandro and Yang, Kaiyu and Deng, Jia},
  booktitle=eccv,
  year={2016},
}

@inproceedings{kato19learning,
	Author = {H. Kato and T. Harada},
	Booktitle = cvpr,
	Title = {Learning View Priors for Single-view 3D Reconstruction},
	Year = {2019}}

@inproceedings{ranjan18generating,
	Author = {A. Ranjan and T. Bolkart and S. Sanyal and M. J. Black},
	Booktitle = eccv,
	Title = {Generating {3D} faces using Convolutional Mesh Autoencoders},
	Year = {2018}}

@inproceedings{gecer19ganfit,
	Author = {B. Gecer and S. Ploumpis and I. Kotsia and S. Zafeiriou},
	Booktitle = cvpr,
	Title = {{GANFIT}: Generative Adversarial Network Fitting for High Fidelity {3D} Face Reconstruction},
	Year = {2019}}

@inproceedings{sanyal19learning,
	Author = {S. Sanyal and T. Bolkart and H. Feng and M. J. Black},
	Booktitle = cvpr,
	Title = {Learning to Regress {3D} Face Shape and Expression from an Image without {3D} Supervision},
	Year = {2019}}

@inproceedings{geng193d-guided,
	Author = {Z. Geng and C. Cao and S. Tulyakov},
	Booktitle = cvpr,
	Title = {{3D} Guided Fine-Grained Face Manipulation},
	Year = {2019}}

@inproceedings{maninis19attentive,
	Author = {Kevis-Kokitsi Maninis and Ilija Radosavovic and Iasonas Kokkinos},
	Booktitle = cvpr,
	Title = {Attentive Single-Tasking of Multiple Tasks},
	Year = {2019}}

@inproceedings{lee19overcoming,
	Author = {Lee, Kibok and Lee, Kimin and Shin, Jinwoo and Lee, Honglak},
	Booktitle = iccv,
	Title = {Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild},
	Year = {2019}}

@book{horn89shape,
	Address = {Cambridge Massachusetts},
	Author = {B. K. P. Horn and M. J. Brooks},
	Publisher = {{MIT} Press},
	Title = {Shape from Shading},
	Year = {1989}}

@inproceedings{novotny19c3dpo,
	Author = {David Novotny and Nikhila Ravi and Benjamin Graham and Natalia Neverova and Andrea Vedaldi},
	Booktitle = iccv,
	Title = {{C3DPO}: Canonical 3D Pose Networks for Non-Rigid Structure From Motion},
	Year = {2019}}

@inproceedings{bregler00recovering,
	Author = {Bregler, Christoph and Hertzmann, Aaron and Biermann, Henning},
	Booktitle = cvpr,
	Title = {Recovering non-rigid {3D} shape from image streams},
	Year = {2000}}

@inproceedings{Moniz2018,
	Author = {Joel Ruben Antony Moniz and Christopher Beckham and Simon Rajotte and Sina Honari and Christopher Pal},
	Booktitle = nips,
	Title = {Unsupervised Depth Estimation, 3D Face Rotation and Replacement},
	Year = {2018}}

@inproceedings{geirhos19imagenet-trained,
	Author = {Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
	Booktitle = icml,
	Title = {ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
	Year = {2019}}

@InProceedings{Suwajanakorn2018,
  author    = {Supasorn Suwajanakorn and Noah Snavely and Jonathan Tompson and Mohammad Norouzi},
  booktitle = nips,
  title     = {Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning},
  year      = {2018},
}

@inproceedings{Shu2018,
	Author = {Zhixin Shu and Mihir Sahasrabudhe and Alp Guler and Dimitris Samaras and Nikos Paragios and Iasonas Kokkinos},
	Booktitle = eccv,
	Title = {Deforming Autoencoders: Unsupervised Disentangling of Shape and Appearance},
	Year = {2018}}

@book{Faugeras01geometry,
	Author = {Olivier Faugeras and Quang-Tuan Luong},
	Publisher = {MIT Press},
	Title = {The Geometry of Multiple Images},
	Year = {2001}}


@inproceedings{Johnson11,
   title = {Learning Effective Human Pose Estimation from Inaccurate Annotation},
   author = {Johnson, Sam and Everingham, Mark},
   year = {2011},
   booktitle = cvpr
}

@InProceedings{mono-3dhp2017,
  author       = {Mehta, Dushyant and Rhodin, Helge and Casas, Dan and Fua, Pascal and Sotnychenko, Oleksandr and Xu, Weipeng and Theobalt, Christian},
  booktitle    = threedv,
  title        = {Monocular 3D Human Pose Estimation In The Wild Using Improved CNN Supervision},
  year         = {2017},
  organization = {IEEE},
  doi          = {10.1109/3dv.2017.00064},
  url          = {http://gvv.mpi-inf.mpg.de/3dhp_dataset},
}

@inproceedings{kinematic-jump-processes,
	author = {Sminchisescu, Cristian and Triggs, Bill},
	title = {Kinematic Jump Processes for Monocular 3D Human Tracking},
	year = {2003},
	isbn = {0769519008},
	publisher = {IEEE Computer Society},
	address = {USA},
	abstract = {A major difficulty for 3D human body tracking from monocular image sequences is the near non-observability of kinematic degrees of freedom that generate motion in depth. For known link (body segment) lengths, the strict non-observabilities reduce to twofold 'forwards/ backwards flipping' ambiguities for each link. These imply 2 # links formal inverse kinematics solutions for the full model, and hence linked groups of O(2 # links) local minima in the model-image matching cost function. Choosing the wrong minimum leads to rapid mistracking, so for reliable tracking, rapid methods of investigating alternative minima within a group are needed. Previous approaches to this have used generic search methods that do not exploit the specific problem structure. Here, we complement these by using simple kinematic reasoning to enumerate the tree of possible forwards/ backwards flips, thus greatly speeding the search within each linked group of minima. Our methods can be used either deterministically, or within stochastic 'jump-diffusion' style search processes. We give experimental results on some challenging monocular human tracking sequences, showing how the new kinematic-flipping based sampling method improves and complements existing ones.},
	booktitle = cvpr,
	pages = {69–76},
	numpages = {8},
	keywords = {monocular 3D human body tracking, kinematic ambiguity, constrained optimization, particle filtering, high-dimensional search, covariance scaled sampling, inverse kinematics},
	location = {Madison, Wisconsin},
	series = {CVPR'03}
}

@inproceedings{tracking-3d-human-figures,
	author = {Sidenbladh, Hedvig and Black, Michael J. and Fleet, David J.},
	title = {Stochastic Tracking of 3D Human Figures Using 2D Image Motion},
	year = {2000},
	isbn = {3540676864},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	abstract = {A probabilistic method for tracking 3D articulated human figures in monocular image sequences is presented. Within a Bayesian framework, we define a generative model of image appearance, a robust likelihood function based on image graylevel differences, and a prior probability distribution over pose and joint angles that models how humans move. The posterior probability distribution over model parameters is represented using a discrete set of samples and is propagated over time using particle filtering. The approach extends previous work on parameterized optical flow estimation to exploit a complex 3D articulated motion model. It also extends previous work on human motion tracking by including a perspective camera model, by modeling limb self occlusion, and by recovering 3D motion from a monocular sequence. The explicit posterior probability distribution represents ambiguities due to image matching, model singularities, and perspective projection. The method relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds.},
	booktitle = eccv,
	pages = {702–718},
	numpages = {17},
	series = {ECCV '00}
}

@inproceedings{density-prop,
	author = {Sminchisescu, C. and Kanaujia, Amit and Li, Zhiguo and Metaxas, Dimitris},
	year = {2005},
	month = {07},
	pages = {390- 397 vol. 1},
	title = {Discriminative density propagation for 3D human motion estimation},
	volume = {1},
	isbn = {0-7695-2372-2},
	journal = cvpr,
	doi = {10.1109/CVPR.2005.132}
}

@inproceedings{xu-2020-cvpr,
  author    = {Xu, Hongyi and Bazavan, Eduard Gabriel and Zanfir, Andrei and Freeman, William and Sukthankar, Rahul and Sminchisescu, Cristian}, 
  title     = {GHUM \& GHUML: Generative 3D Human Shape and Articulated Pose Models},
  booktitle   = cvpr,
  year      = {2020},
}

@inproceedings{weakly-supervised-normflow,
  author    = {Zanfir, Andrei and Bazavan, Eduard Gabriel and Xu, Hongyi and Freeman, William and Sukthankar, Rahul and Sminchisescu, Cristian}, 
  title     = {Weakly Supervised 3D Human Pose and Shape Reconstruction with Normalizing Flows},
  booktitle   = eccv,
  year      = {2020},
}

@Article{deeplabv3plus,
  author       = {Liang{-}Chieh Chen and Yukun Zhu and George Papandreou and Florian Schroff and Hartwig Adam},
  title        = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation},
  year         = {2018},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  biburl       = {https://dblp.org/rec/bib/journals/corr/abs-1802-02611},
  eprint       = {1802.02611},
  journaltitle = eccv,
  timestamp    = {Mon, 13 Aug 2018 16:47:38 +0200},
}


@article{park2017general,
	author = {Park, Jaehyun and Boyd, Stephen},
	year = {2017},
	month = {03},
	pages = {},
	title = {General Heuristics for Nonconvex Quadratically Constrained Quadratic Programming}
}

@misc{adobe_ultrakey,
	title={Creating a green screen key using Ultra key},
	author={{A}dobe {S}ystems {I}nc.},
	year={2018},
	howpublished={\url{https://helpx.adobe.com/premiere-pro/atv/cs5-cs55-video-tutorials/creating-a-green-screen-key-using-ultra-key.html}},
	note={Accessed: 2018-03-14}
}


@inproceedings{lourakis2005levenberg,
  title={Is {Levenberg-Marquardt} the most efficient optimization algorithm for implementing bundle adjustment?},
  author={Lourakis, MLA and Argyros, Antonis A},
  booktitle=iccv,
  pages={1526--1531},
  year={2005},
}

@misc{vium_inc,
  title={Breathing Rate},
  author={{Vium Inc}},
  year={2017},
  month={Nov},
  note = {Online; accessed 15-December-2016}}

@inproceedings{bogo2014faust,
  title={{FAUST}: Dataset and evaluation for {3D} mesh registration},
  author={Bogo, Federica and Romero, Javier and Loper, Matthew and Black, Michael J},
  booktitle=cvpr,
  pages={3794--3801},
  year={2014}
}

@inproceedings{NB13,
  author       = "F. Galasso and N.S. Nagaraja and T.J. Cardenas and T. Brox and B.Schiele",
  title        = "A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis",
  booktitle    = iccv,
  month        = "Dec",
  year         = "2013",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2013/NB13"
}

@InProceedings{wiles2017silnet,
  author       = "Wiles, O. and Zisserman, A.",
  title        = "SilNet : Single- and Multi-View Reconstruction by Learning from Silhouettes",
  booktitle    = bmvc,
  year         = "2017",
}

@inproceedings{Perazzi2016,
  author = {F. Perazzi and J. Pont-Tuset and B. McWilliams and L. {Van Gool} and M. Gross and A. Sorkine-Hornung},
  title = {A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation},
  booktitle = cvpr,
  year = {2016}
}

@inproceedings{imagenet_cvpr09,
  AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  BOOKTITLE = cvpr,
  YEAR = {2009},
  BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@inproceedings{loper2014opendr,
  title={{OpenDR}: An approximate differentiable renderer},
  author={Loper, Matthew M and Black, Michael J},
  booktitle=eccv,
  pages={154--169},
  year={2014},
  organization={Springer}
}

@Article{cashman2013shape,
  author    = {Cashman, Thomas J and Fitzgibbon, Andrew W},
  journal   = pami,
  title     = {What shape are dolphins? {B}uilding {3D} morphable models from {2D} images},
  year      = {2013},
  number    = {1},
  pages     = {232--244},
  volume    = {35},
  publisher = {IEEE},
}

@article{diamond2016cvxpy,
  author  = {Steven Diamond and Stephen Boyd},
  title   = {{CVXPY}: A {P}ython-Embedded Modeling Language for Convex Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
}

@inproceedings{chen2010inferring,
  title={Inferring {3D} shapes and deformations from single views},
  author={Chen, Yu and Kim, Tae-Kyun and Cipolla, Roberto},
  booktitle=eccv,
  pages={300--313},
  year={2010},
  organization={Springer}
}

@inproceedings{andriluka2010monocular,
  title={Monocular {3D} pose estimation and tracking by detection},
  author={Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
  booktitle=cvpr,
  pages={623--630},
  year={2010},
  organization={IEEE}
}

@inproceedings{pishchulin2013poselet,
  title={Poselet conditioned pictorial structures},
  author={Pishchulin, Leonid and Andriluka, Mykhaylo and Gehler, Peter and Schiele, Bernt},
  booktitle=cvpr,
  pages={588--595},
  year={2013},
  organization={IEEE}
}

@inproceedings{johnson2010clustered,
   title = {Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation},
   author = {Johnson, Sam and Everingham, Mark},
   year = {2010},
   pages = {12.1--12.11},
   booktitle = bmvc,
   editors = {Labrosse, Fr\'ed\'eric and Zwiggelaar, Reyer and Liu, Yonghuai and Tiddeman, Bernie},
}

@inproceedings{cao2017realtime,
  title={Realtime multi-person {2D} pose estimation using part affinity fields},
  author={Cao, Zhe and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  booktitle=cvpr,
  year={2017}
}
@inproceedings{favreau2004animal,
  title={Animal gaits from video},
  author={Favreau, Laurent and Reveret, Lionel and Depraz, Christine and Cani, Marie-Paule},
  booktitle=siggraph,
  pages={277--286},
  year={2004}
}

@inproceedings{bulat2016human,
  title={Human pose estimation via convolutional part heatmap regression},
  author={Bulat, Adrian and Tzimiropoulos, Georgios},
  booktitle=eccv,
  pages={717--732},
  year={2016},
  organization={Springer}
}

@InProceedings{chen_cvpr14,
 author       = {Xianjie Chen and Roozbeh Mottaghi and Xiaobai Liu and Sanja Fidler and Raquel Urtasun and Alan Yuille},
 title        = {Detect What You Can: Detecting and Representing Objects using Holistic Models and Body Parts},
 booktitle    = cvpr,
 year         = {2014},
}

@inproceedings{wilhelm2015furyexplorer,
  title={Furyexplorer: visual-interactive exploration of horse motion capture data},
  author={Wilhelm, Nils and V{\"o}gele, Anna and Zsoldos, Rebeka and Licka, Theresia and Kr{\"u}ger, Bj{\"o}rn and Bernard, J{\"u}rgen},
  booktitle={Visualization and Data Analysis 2015},
  volume={9397},
  pages={93970F},
  year={2015}
}

@inproceedings{zhou2017scene,
    title={Scene Parsing through {ADE20K} Dataset},
    author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
    booktitle=cvpr,
    year={2017}
}

@inproceedings{zuffi_lions,
    title = {Lions and Tigers and Bears: Capturing Non-Rigid, {3D}, Articulated Shape from Images},
    author = {Zuffi, Silvia and Kanazawa, Angjoo and Black, Michael J.},
    booktitle = cvpr,
    year = {2018}
}

@inproceedings{viazzi2013using,
  author = {Viazzi, Stefano and Van Hertem, Tom and Schlagater-Tello, A and Bahr, C. and Romanini, C and Halachmi, Ilan and Lokhorst, C and Berckmans, Daniel},
  year = {2013},
  month = {01},
  pages = {},
  title = {Using a 3D camera to evaluate the back posture of dairy cows},
  volume = {5},
  journal = {American Society of Agricultural and Biological Engineers Annual International Meeting 2013, ASABE 2013},
  doi = {10.13031/aim.20131620172}
}

@InProceedings{andriluka14cvpr,
  author    = {Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and Schiele, Bernt},
  booktitle = cvpr,
  title     = {{2D} human pose estimation: New benchmark and state of the art analysis},
  year      = {2014},
  month     = {June},
}

@InProceedings{wang2015joint,
  author    = {Wang, Peng and Shen, Xiaohui and Lin, Zhe and Cohen, Scott and Price, Brian and Yuille, Alan L},
  booktitle = iccv,
  title     = {Joint object and part segmentation using deep learned potentials},
  year      = {2015},
  pages     = {1573--1581},
}

@InProceedings{wang2015semantic,
  author    = {Wang, Jianyu and Yuille, Alan L},
  booktitle = cvpr,
  title     = {Semantic part segmentation using compositional model combining shape and appearance},
  year      = {2015},
  pages     = {1788--1797},
}

@InProceedings{zuffi2017menagerie,
  author        = {Zuffi, Silvia and Kanazawa, Angjoo and Jacobs, David and Black, Michael J.},
  booktitle     = cvpr,
  title         = {{3D} Menagerie: Modeling the {3D} Shape and Pose of Animals},
  year          = {2017},
  pages         = {5524--5532},
  publisher     = {IEEE},
  month_numeric = {7},
}

@Article{yang2013articulated,
  author    = {Yang, Yi and Ramanan, Deva},
  journal   = pami,
  title     = {Articulated human detection with flexible mixtures of parts},
  year      = {2013},
  number    = {12},
  pages     = {2878--2890},
  volume    = {35},
  publisher = {IEEE},
}

@article{blum1967transformation,
  title={A transformation for extracting new descriptors of shape},
  author={Blum, Harry},
  journal={Models for Perception of Speech and Visual Forms, 1967},
  pages={362--380},
  year={1967}
}

@book{holland1992adaptation,
  title={Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence},
  author={Holland, John Henry},
  year={1992},
  publisher={MIT press}
}

@InProceedings{shotton-kinect,
  author    = {Shotton, Jamie and Fitzgibbon, Andrew and Blake, Andrew and Kipman, Alex and Finocchio, Mark and Moore, Bob and Sharp, Toby},
  booktitle = cvpr,
  title     = {Real-Time Human Pose Recognition in Parts from a Single Depth Image},
  year      = {2011},
  month     = {June},
  publisher = {IEEE},
}

@article{mathis2018deeplabcut,
  title={DeepLabCut: markerless pose estimation of user-defined body parts with deep learning},
  author = {Alexander Mathis and Pranav Mamidanna and Kevin M. Cury and Taiga Abe  and Venkatesh N. Murthy and Mackenzie W. Mathis and Matthias Bethge},
  journal={Nature Neuroscience},
  year={2018},
  url={https://www.nature.com/articles/s41593-018-0209-y}
}

@book{appa20,
  year = 2020,
  key = {American Pet Products Association},
  title = {2019-2020 {APPA} National Pet Owners Survey}, 
  author = {{American Pet Products Association}}, 
  note = {http://www.americanpetproducts.org}
}

@misc{FAOSTAT,
  author  = {{Food and Agriculture Organization of the United Nations}},
  title = {{FAOSTAT} Statistics Database},
  year = "2016",
  url = "\url={http://www.fao.org/faostat/en/#data/QL}",
  note = "[Online; data retrieved from {FAOSTAT} on 21-November-2017]"
}

@article{rodriquez2017toxtrac,
  author = {Rodriguez, Alvaro and Zhang, Hanqing and Klaminder, Jonatan and Brodin, Tomas and Andersson, Patrik and Andersson, Magnus},
  year = {2018},
  month = {03},
  pages = {460–464},
  title = {ToxTrac: A fast and robust software for tracking organisms},
  volume = {9},
  journal = {Methods in Ecology and Evolution},
  doi = {10.1111/2041-210x.12874}
}

@article{zammit2010reliability,
  title={Reliability of the {TekScan MatScan}{\textregistered} system for the measurement of plantar forces and pressures during barefoot level walking in healthy adults},
  author={Zammit, Gerard V and Menz, Hylton B and Munteanu, Shannon E},
  journal={Journal of foot and ankle research},
  volume={3},
  number={1},
  pages={11},
  year={2010},
  publisher={BioMed Central}
}

@article{tort2006simple,
  title={A simple webcam-based approach for the measurement of rodent locomotion and other behavioural parameters},
  author={Tort, Adriano BL and Neto, Waldemar P and Amaral, Olavo B and Kazlauckas, Vanessa and Souza, Diogo O and Lara, Diogo R},
  journal={Journal of neuroscience methods},
  volume={157},
  number={1},
  pages={91--97},
  year={2006},
  publisher={Elsevier}
}

@article{DAVIS2017-1st,
  author = {X. Li and Y. Qi and Z. Wang and K. Chen and Z. Liu and J. Shi and P. Luo and C. Change Loy and X. Tang},
  title = {Video Object Segmentation with Re-identification},
  journal = {The 2017 DAVIS Challenge on Video Object Segmentation - CVPR Workshops},
  year = {2017}
}

@article{DAVIS2017-2nd,
  author = {A. Khoreva and R. Benenson and E. Ilg and T. Brox and B. Schiele},
  title = {Lucid Data Dreaming for Object Tracking},
  journal = {The 2017 DAVIS Challenge on Video Object Segmentation - CVPR Workshops},
  year = {2017}
}

@article{zhou2016semantic,
  title={Semantic understanding of scenes through the ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  journal={International Journal of Computer Vision},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=cvpr,
  pages={770--778},
  year={2016}
}

@InProceedings{biggs2018creatures,
  author    = {Biggs, Benjamin and Roddick, Thomas and Fitzgibbon, Andrew and Cipolla, Roberto},
  booktitle = accv,
  title     = {{C}reatures {G}reat and {SMAL}: {R}ecovering the shape and motion of animals from video},
  year      = {2018},
}

@InProceedings{Zuffi19Safari,
  author    = {Zuffi, Silvia and Kanazawa, Angjoo and Berger-Wolf, Tanja and Black, Michael J.},
  booktitle = iccv,
  title     = {Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images "In the Wild"},
  year      = {2019},
}

@InProceedings{han2017viton,
  author    = {Han, Xintong and Wu, Zuxuan and Wu, Zhe and Yu, Ruichi and Davis, Larry S},
  booktitle = cvpr,
  title     = {VITON: An Image-based Virtual Try-on Network},
  year      = {2018},
}

@Article{pifuSHNMKL19,
  author  = {Shunsuke Saito and and Zeng Huang and Ryota Natsume and Shigeo Morishima and Angjoo Kanazawa and Hao Li},
  booktitle = iccv,
  title   = {PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization},
  year    = {2019},
}


@InProceedings{alldieck2019learning,
  author    = {Alldieck, Thiemo and Magnor, Marcus and Bhatnagar, Bharat Lal and Theobalt, Christian and Pons-Moll, Gerard},
  booktitle = cvpr,
  title     = {Learning to reconstruct people in clothing from a single RGB camera},
  year      = {2019},
  pages     = {1175--1186},
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International Journal of Computer Vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

@inproceedings{StanfordDogs,
  author = "Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei",
  title = "Novel Dataset for Fine-Grained Image Categorization",
  booktitle = "First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition",
  year = "2011",
  month = "June",
  address = "Colorado Springs, CO",
}

@InProceedings{kato2018renderer,
  title={Neural 3D Mesh Renderer},
  author={Kato, Hiroharu and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle=cvpr,
  year={2018}
}

@InProceedings{animalpose,
  author={J. {Cao} and H. {Tang} and H. {Fang} and X. {Shen} and Y. {Tai} and C. {Lu}},
  booktitle=iccv, 
  title={Cross-Domain Adaptation for Animal Pose Estimation}, 
  year={2019},
  volume={},
  number={},
  pages={9497-9506},}

@InProceedings{Kearney_2020_CVPR,
  author = {Kearney, Sinead and Li, Wenbin and Parsons, Martin and Kim, Kwang In and Cosker, Darren},
  title = {RGBD-Dog: Predicting Canine Pose from RGBD Sensors},
  booktitle=cvpr,
  month = {June},
  year = {2020}
}

@InProceedings{Agudo_2018_CVPR,
  author = {Agudo, Antonio and Pijoan, Melcior and Moreno-Noguer, Francesc},
  title = {Image Collection Pop-Up: 3D Reconstruction and Clustering of Rigid and Non-Rigid Categories},
  booktitle=cvpr,
  month = {June},
  year = {2018}
}

@inproceedings{Probst2018_ECCVa,
  author = "Probst, Thomas and Pani Paudel, Danda and Chhatkuli, Ajad and Van Gool, Luc",
  title = "Incremental Non-Rigid Structure-from-Motion with Unknown Focal Length",
  booktitle = eccv,
  year = "2018"
}

@InProceedings{vicente_3dv,
  author    = {S. {Vicente} and L. {Agapito}},
  booktitle = threedv,
  title     = {Balloon Shapes: Reconstructing and Deforming Objects with Volume from Images},
  year      = {2013},
  pages     = {223-230},
}

@misc{SWOH-Tilikum,
    author = {{SeaWorld of Hurt}},
    title = "Over 30 Years and Three Deaths: Tilikum’s Tragic Story",
    year = "1999",
    url = "https://www.seaworldofhurt.com/features/30-years-three-deaths-tilikums-tragic-story/",
    note = "[Online; accessed 27-November-2017]"
  }

@misc{Guardian-Elephant,
  author = "Radford, Tim",
  title = "Short, unhappy life for elephants kept in zoos",
  editor = "The Guardian",
  year = "1999",
  month = "October",
  url = "\url{https://www.theguardian.com/uk/2002/oct/23/animalwelfare.world}",
  note = "[Online; accessed 27-November-2017]"
}

@misc{arap_stebbing, 
  author={Richard Stebbing and 
          Andrew Fitzgibbon}, 
  year={2017}, 
  month={Jan},
  howpublished = {Personal communication}}

@inproceedings{lin2014digital,
  title={Digital Human Modeling and Clothing Virtual Try-on},
  author={Lin, Yueh-Ling and Wang, Mao-Jiun J},
  booktitle={Proceedings of the 2014 International Conference on Industrial Engineering and Operations Management Bali, Indonesia},
  year={2014}
}

@article{Streuber:SIGGRAPH:2016,
  title = {{Body Talk}: Crowdshaping Realistic {3D} Avatars with Words},
  author = {Streuber, Stephan and Quiros-Ramirez, M. Alejandra and Hill, Matthew Q. and Hahn, Carina A. and Zuffi, Silvia and O’Toole, Alice and Black, Michael J.},
  journal = siggraph,
  volume = {35},
  number = {4},
  pages = {54:1--54:14},
  month = {Jul},
  year = {2016},
  month_numeric = {7}
}

@article{Bai:2009:VSC,
  author = {Xue Bai and Jue Wang and David Simons and Guillermo Sapiro},
  title = {Video {S}nap{C}ut: {R}obust {V}ideo {O}bject {C}utout {U}sing {L}ocalized {C}lassifiers},
  journal = {ACM Trans.~Graphics},
  year = {2009}
}

@inproceedings{velardo2010weight,
  title={Weight estimation from visual body appearance},
  author={Velardo, Carmelo and Dugelay, Jean-Luc},
  booktitle={Biometrics: {T}heory Applications and Systems (BTAS), 2010 Fourth IEEE International Conference on},
  pages={1--6},
  year={2010},
  organization={IEEE}
}

@inproceedings{laine2017production,
  title={Production-level facial performance capture using deep convolutional neural networks},
  author={Laine, Samuli and Karras, Tero and Aila, Timo and Herva, Antti and Saito, Shunsuke and Yu, Ronald and Li, Hao and Lehtinen, Jaakko},
  booktitle=siggraph,
  pages={10},
  year={2017},
  organization={ACM}
}

@article{khoshelham2012accuracy,
  title={Accuracy and resolution of {K}inect depth data for indoor mapping applications},
  author={Khoshelham, Kourosh and Elberink, Sander Oude},
  journal={Sensors},
  volume={12},
  number={2},
  pages={1437--1454},
  year={2012},
  publisher={Molecular Diversity Preservation International}
}

@article{weizmann,
  title={Combined top-down/bottom-up segmentation},
  author={Borenstein, Eran and Ullman, Shimon},
  journal=pami,
  volume={30},
  number={12},
  pages={2109--2125},
  year={2008},
  publisher={IEEE}
}

@inproceedings{oxfordpetdata,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle=cvpr,
  pages={3498--3505},
  year={2012},
  organization={IEEE}
}

@inproceedings{xxx,
  title={TODO},
  author={Benjamin Biggs},
  booktitle=cvpr,
  year = {2020}
}

@InProceedings{Khamis_2015_CVPR,
  author    = {Khamis, Sameh and Taylor, Jonathan and Shotton, Jamie and Keskin, Cem and Izadi, Shahram and Fitzgibbon, Andrew},
  booktitle = cvpr,
  title     = {Learning an Efficient Model of Hand Shape Variation From Depth Images},
  year      = {2015},
  month     = {June},
  publisher = {IEEE},
  abstract  = {We describe how to learn a compact and efficient model of the surface deformation of human hands. The model is built from a set of noisy depth images of a diverse set of subjects performing different poses with their hands. We represent the observed surface using Loop subdivision of a control mesh that is deformed by our learned parametric shape and pose model. The model simultaneously accounts for variation in subject-specific shape and subject-agnostic pose. Specifically, hand shape is parameterized as a linear combination of a mean mesh in a neutral pose with a small number of offset vectors. This mesh is then articulated using standard linear blend skinning (LBS) to generate the control mesh of a subdivision surface. We define an energy that encourages each depth pixel to be explained by our model, and the use of a smooth subdivision surface allows us to optimize for all parameters jointly from a rough initialization. The efficacy of our method is demonstrated using both synthetic and real data, where it is shown that hand shape variation can be represented using only a small number of basis components. We compare with other approaches including PCA and show a substantial improvement in the representational power of our model, while maintaining the efficiency of a linear shape basis.},
  url       = {https://www.microsoft.com/en-us/research/publication/learning-an-efficient-model-of-hand-shape-variation-from-depth-images/},
}

@InProceedings{kanazawa2018birds,
  author    = {Angjoo Kanazawa and Shubham Tulsiani and Alexei A. Efros and Jitendra Malik},
  booktitle = eccv,
  title     = {Learning Category-Specific Mesh Reconstruction from Image Collections},
  year      = {2018},
  pages     = {371--386},
}

@InProceedings{reinert2016animated,
  author    = {Reinert, Bernhard and Ritschel, Tobias and Seidel, Hans-Peter},
  booktitle = {Graphics Interface},
  title     = {Animated {3D} Creatures from Single-view Video by Skeletal Sketching.},
  year      = {2016},
  pages     = {133--141},
}


@article{pose-hogg,
	title = {Model-based vision: a program to see a walking person},
	volume = {1},
	issn = {0262-8856},
	url = {https://www.sciencedirect.com/science/article/pii/0262885683900033},
	doi = {https://doi.org/10.1016/0262-8856(83)90003-3},
	abstract = {For a machine to be able to ‘see’, it must know something about the object it is ‘looking’ at. A common method in machine vision is to provide the machine with general rather than specific knowledge about the object. An alternative technique, and the one used in this paper, is a model-based approach in which particulars about the object are given and this drives the analysis. The computer program described here, the WALKER model, maps images into a description in which a person is represented by the series of hierarchical levels, i.e. a person has an arm which has a lower-arm which has a hand. The performance of the program is illustrated by superimposing the machine-generated picture over the original photographic images.},
	number = {1},
	journal = {Image and Vision Computing},
	author = {Hogg, David},
	year = {1983},
	keywords = {machine perception, vision, WALKER model},
	pages = {5--20},
}

@article{pictorial-structures,
author = {Fischler, M. A. and Elschlager, R. A.},
title = {The Representation and Matching of Pictorial Structures},
year = {1973},
issue_date = {January 1973},
publisher = {IEEE Computer Society},
address = {USA},
volume = {22},
number = {1},
issn = {0018-9340},
url = {https://doi.org/10.1109/T-C.1973.223602},
doi = {10.1109/T-C.1973.223602},
abstract = {The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of "goodness" of matching or detection.},
journal = {IEEE Trans. Comput.},
month = jan,
pages = {67–92},
numpages = {26},
keywords = {heuristic optimization, picture processing, picture matching, representation., Dynamic programming, picture description}
}

@INPROCEEDINGS{pose-johnson-mixtureparts,
  author={S. {Johnson} and M. {Everingham}},
  booktitle={CVPR 2011}, 
  title={Learning effective human pose estimation from inaccurate annotation}, 
  year={2011},
  volume={},
  number={},
  pages={1465-1472},
  doi={10.1109/CVPR.2011.5995318}}

@article{human-rep-parts,
	title = {Description and recognition of curved objects},
	volume = {8},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/0004370277900066},
	doi = {https://doi.org/10.1016/0004-3702(77)90006-6},
	abstract = {Analysis of scenes of three-dimensional objects has, in the past, been largely limited to the world of polyhedra. Techniques for generating structured, symbolic descriptions of complex curved objects by segmenting them into simpler sub-parts are presented here. The complexity of objects used is that of toy animals and hand tools. Recognition is performed by matching these descriptions with stored descriptions of models. A laser ranging techniques is used to acquire three-dimensional position of points on the visible surfaces. Successful segmentation and recognition results have been obtained for scenes with multiple, occluding objects in various orientations and with a variety of articulations of sub-parts.},
	number = {1},
	journal = {Artificial Intelligence},
	author = {Nevatia, Ramakant and Binford, Thomas O.},
	year = {1977},
	pages = {77--98},
}


@article{corres-stereo,
  author = {Hannah, Marsha Jo},
  title = {Computer Matching of Areas in Stereo Images.},
  year = {1974},
  publisher = {Stanford University},
  address = {Stanford, CA, USA},
  note = {AAI7427032}
}


@article{corres-optflow,
  author = {Horn, Berthold K. P. and Schunck, Brian G.},
  title = {Determining Optical Flow},
  year = {1981},
  issue_date = {August 1981},
  publisher = {Elsevier Science Publishers Ltd.},
  address = {GBR},
  volume = {17},
  number = {1–3},
  issn = {0004-3702},
  url = {https://doi.org/10.1016/0004-3702(81)90024-2},
  doi = {10.1016/0004-3702(81)90024-2},
  journal = {Artifical Intelligence},
  month = aug,
  pages = {185–203},
  numpages = {19}
}

@article{sift,
  author = {Lowe, David G.},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  year = {2004},
  issue_date = {November 2004},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  volume = {60},
  number = {2},
  issn = {0920-5691},
  url = {https://doi.org/10.1023/B:VISI.0000029664.99615.94},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  journal = {International Journal of Computer Vision},
  month = nov,
  pages = {91–110},
  numpages = {20},
  keywords = {object recognition, image matching, invariant features, scale invariance}
}

@inproceedings{hog,
  author = {Dalal, Navneet and Triggs, Bill},
  title = {Histograms of Oriented Gradients for Human Detection},
  year = {2005},
  isbn = {0769523722},
  publisher = {IEEE Computer Society},
  address = {USA},
  url = {https://doi.org/10.1109/CVPR.2005.177},
  doi = {10.1109/CVPR.2005.177},
  booktitle = cvpr,
  pages = {886–893},
  numpages = {8},
  series = {CVPR '05}
}

@article{daisy,
  author = {Tola, Engin and Lepetit, Vincent and Fua, Pascal},
  title = {DAISY: An Efficient Dense Descriptor Applied to Wide-Baseline Stereo},
  year = {2010},
  issue_date = {May 2010},
  publisher = {IEEE Computer Society},
  address = {USA},
  volume = {32},
  number = {5},
  issn = {0162-8828},
  url = {https://doi.org/10.1109/TPAMI.2009.77},
  doi = {10.1109/TPAMI.2009.77},
  journal = pami,
  month = may,
  pages = {815–830},
  numpages = {16},
  keywords = {local descriptors., dense depth map estimation, Image processing and computer vision}
}

@inproceedings{vlad,
  author = {Arandjelovic, Relja and Zisserman, Andrew},
  title = {All About VLAD},
  year = {2013},
  isbn = {9780769549897},
  publisher = {IEEE Computer Society},
  address = {USA},
  url = {https://doi.org/10.1109/CVPR.2013.207},
  doi = {10.1109/CVPR.2013.207},
  abstract = {The objective of this paper is large scale object instance retrieval, given a query image. A starting point of such systems is feature detection and description, for example using SIFT. The focus of this paper, however, is towards very large scale retrieval where, due to storage requirements, very compact image descriptors are required and no information about the original SIFT descriptors can be accessed directly at run time. We start from VLAD, the state-of-the art compact descriptor introduced by Jegou et al. for this purpose, and make three novel contributions: first, we show that a simple change to the normalization method significantly improves retrieval performance, second, we show that vocabulary adaptation can substantially alleviate problems caused when images are added to the dataset after initial vocabulary learning. These two methods set a new state-of-the-art over all benchmarks investigated here for both mid-dimensional (20k-D to 30k-D) and small (128-D) descriptors. Our third contribution is a multiple spatial VLAD representation, MultiVLAD, that allows the retrieval and localization of objects that only extend over a small part of an image (again without requiring use of the original image SIFT descriptors).},
  booktitle = cvpr,
  pages = {1578–1585},
  numpages = {8},
  series = {CVPR '13}
}

@inproceedings{corner-detector,
    author = {Chris Harris and Mike Stephens},
    title = {A combined corner and edge detector},
    booktitle = {Proc. of Fourth Alvey Vision Conference},
    year = {1988},
    pages = {147--151}
}

@techreport{corner-moravec,
  author = {Hans Moravec},
  title = {Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover},
  year = {1980},
  month = {September},
  institution = {Carnegie Mellon University},
  address = {Pittsburgh, PA},
}

@inproceedings{corner-harris,
  added-at = {2009-06-09T19:58:38.000+0200},
  author = {Harris, C. and Stephens, M.},
  biburl = {https://www.bibsonomy.org/bibtex/22d2048f92453ed8d1426782cfe774b62/zap},
  booktitle = {Proceedings of the 4th Alvey Vision Conference},
  description = {MAPS citations},
  interhash = {69457ee9c61699b5153f9481a6c7f4bb},
  intrahash = {2d2048f92453ed8d1426782cfe774b62},
  keywords = {imported visual-interest-points},
  pages = {147--151},
  timestamp = {2009-06-09T23:55:27.000+0200},
  title = {A Combined Corner and Edge Detector},
  year = 1988
}

@article{corner-susan,
  author = {S. M. Smith and J. M. Brady},
  title = {SUSAN - A New Approach to Low Level Image Processing},
  journal = {International Journal of Computer Vision},
  year = {1995},
  volume = {23},
  pages = {45--78}
}

@InProceedings{lift,
  author="Yi, Kwang Moo
  and Trulls, Eduard
  and Lepetit, Vincent
  and Fua, Pascal",
  editor="Leibe, Bastian
  and Matas, Jiri
  and Sebe, Nicu
  and Welling, Max",
  title="LIFT: Learned Invariant Feature Transform",
  booktitle=eccv,
  year="2016",
  publisher="Springer International Publishing",
  address="Cham",
  pages="467--483",
  abstract="We introduce a novel Deep Network architecture that implements the full feature point handling pipeline, that is, detection, orientation estimation, and feature description. While previous works have successfully tackled each one of these problems individually, we show how to learn to do all three in a unified manner while preserving end-to-end differentiability. We then demonstrate that our Deep pipeline outperforms state-of-the-art methods on a number of benchmark datasets, without the need of retraining.",
  isbn="978-3-319-46466-4"
}

@inproceedings{matchnet,
  Author = {Han, Xufeng and Leung, Thomas and Jia, Yangqing and Sukthankar, Rahul and Berg, Alexander. C.},
  Booktitle = cvpr,
  Title = {MatchNet: Unifying Feature and Metric Learning for Patch-Based Matching},
  Year = {2015}
} 

@article{surf,
  author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Van Gool, Luc},
  title = {Speeded-Up Robust Features (SURF)},
  year = {2008},
  issue_date = {June, 2008},
  publisher = {Elsevier Science Inc.},
  address = {USA},
  volume = {110},
  number = {3},
  issn = {1077-3142},
  url = {https://doi.org/10.1016/j.cviu.2007.09.014},
  doi = {10.1016/j.cviu.2007.09.014},
  abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision.},
  journal = {Computer Vision and Image Understanding},
  month = jun,
  pages = {346–359},
  numpages = {14},
  keywords = {Local features, Object recognition, Feature description, Camera calibration, Interest points}
}

@article{sift-3d,
  author={B. {Rister} and M. A. {Horowitz} and D. L. {Rubin}},
  journal={IEEE Transactions on Image Processing}, 
  title={Volumetric Image Registration From Invariant Keypoints}, 
  year={2017},
  volume={26},
  number={10},
  pages={4900-4910},
  doi={10.1109/TIP.2017.2722689}
}


@Comment(POSE ESIMTATION)
@inproceedings{pose-kposelets,
 Author = {G. Gkioxari and B. Hariharan and R. Girshick and J. Malik},
 Title = {Using k-poselets for detecting people and localizing their keypoints},
 Booktitle = {CVPR},
 Year = {2014}}

@article{pose-felzen,
  author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  title = {Pictorial Structures for Object Recognition},
  year = {2005},
  issue_date = {January 2005},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  volume = {61},
  number = {1},
  issn = {0920-5691},
  url = {https://doi.org/10.1023/B:VISI.0000042934.15159.49},
  doi = {10.1023/B:VISI.0000042934.15159.49},
  abstract = {In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.},
  journal = {International Journal of Computer Vision},
  month = jan,
  pages = {55–79},
  numpages = {25},
  keywords = {energy minimization, part-based object recognition, statistical models}
}

@inproceedings{liu2012dog,
  title={Dog breed classification using part localization},
  author={Liu, Jiongxin and Kanazawa, Angjoo and Jacobs, David and Belhumeur, Peter},
  booktitle=eccv,
  pages={172--185},
  year={2012},
  organization={Springer}
}

@techreport{WelinderEtal2010,
	Author = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2010-001},
	Title = {{Caltech-UCSD Birds 200}},
	Year = {2010}
}

@inproceedings{pose-embedding,
 author = {Taylor, Graham W and Fergus, Rob and Williams, George and Spiro, Ian and Bregler, Christoph},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Pose-Sensitive Embedding by Nonlinear NCA Regression},
 url = {https://proceedings.neurips.cc/paper/2010/file/d56b9fc4b0f1be8871f5e1c40c0067e7-Paper.pdf},
 volume = {23},
 year = {2010}
}

@inproceedings{pose-face-earlycnn,
author = {Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
title = {Deep Convolutional Network Cascade for Facial Point Detection},
year = {2013},
isbn = {9780769549897},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CVPR.2013.446},
doi = {10.1109/CVPR.2013.446},
abstract = {We propose a new approach for estimation of the positions of facial key points with three-level carefully designed convolutional networks. At each level, the outputs of multiple networks are fused for robust and accurate estimation. Thanks to the deep structures of convolutional networks, global high-level features are extracted over the whole face region at the initialization stage, which help to locate high accuracy key points. There are two folds of advantage for this. First, the texture context information over the entire face is utilized to locate each key point. Second, since the networks are trained to predict all the key points simultaneously, the geometric constraints among key points are implicitly encoded. The method therefore can avoid local minimum caused by ambiguity and data corruption in difficult image samples due to occlusions, large pose variations, and extreme lightings. The networks at the following two levels are trained to locally refine initial predictions and their inputs are limited to small regions around the initial predictions. Several network structures critical for accurate and robust facial point detection are investigated. Extensive experiments show that our approach outperforms state-of-the-art methods in both detection accuracy and reliability.},
booktitle = {Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition},
pages = {3476–3483},
numpages = {8},
keywords = {Convolutional Network, Facial Point Detection},
series = {CVPR '13}
}

@InProceedings{Pfister15,
  author       = "Pfister, T. and Charles, J. and Zisserman, A.",
  title        = "Flowing ConvNets for Human Pose Estimation in Videos",
  booktitle    = "International Conference on Computer Vision",
  year         = "2015",
}

@InProceedings{Pfister14a,
  author       = "Pfister, T. and Simonyan, K. and Charles, J. and Zisserman, A.",
  title        = "Deep Convolutional Neural Networks for Efficient Pose Estimation in Gesture Videos",
  booktitle    = "Asian Conference on Computer Vision",
  year         = "2014",
}

@InProceedings{Charles16,
  author       = "Charles, J. and Pfister, T. and Magee, D. and Hogg, D. Zisserman, A.",
  title        = "Personalizing Human Video Pose Estimation",
  booktitle    = "Conference on Computer Vision and Pattern Recognition",	
  year         = "2016",
}

@inproceedings{joint-training,
author = {Tompson, Jonathan and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
title = {Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {This paper proposes a new hybrid architecture that consists of a deep Convolu-tional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1799–1807},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'14}
}

@inproceedings{viewpoints-keypoints,
  author={S. {Tulsiani} and J. {Malik}},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Viewpoints and keypoints}, 
  year={2015},
  volume={},
  number={},
  pages={1510-1519},
  doi={10.1109/CVPR.2015.7298758}
}

@inproceedings{wei2016cpm,
    author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
    booktitle = {CVPR},
    title = {Convolutional pose machines},
    year = {2016}
}

@InProceedings{Xiao_2018_ECCV,
author = {Xiao, Bin and Wu, Haiping and Wei, Yichen},
title = {Simple Baselines for Human Pose Estimation and Tracking},
booktitle = eccv,
month = {September},
year = {2018}
}

@article{2dpose-survey-1,
  title = {Vision-based human motion analysis: An overview},
  journal = {Computer Vision and Image Understanding},
  volume = {108},
  number = {1},
  pages = {4-18},
  year = {2007},
  note = {Special Issue on Vision for Human-Computer Interaction},
  issn = {1077-3142},
  doi = {https://doi.org/10.1016/j.cviu.2006.10.016},
  url = {https://www.sciencedirect.com/science/article/pii/S1077314206002293},
  author = {Ronald Poppe},
  keywords = {Human motion analysis, Pose estimation, Computer vision},
  abstract = {Markerless vision-based human motion analysis has the potential to provide an inexpensive, non-obtrusive solution for the estimation of body poses. The significant research effort in this domain has been motivated by the fact that many application areas, including surveillance, Human–Computer Interaction and automatic annotation, will benefit from a robust solution. In this paper, we discuss the characteristics of human motion analysis. We divide the analysis into a modeling and an estimation phase. Modeling is the construction of the likelihood function, estimation is concerned with finding the most likely pose given the likelihood surface. We discuss model-free approaches separately. This taxonomy allows us to highlight trends in the domain and to point out limitations of the current state of the art.}
}

@article{2dpose-survey-2,
  author={Q. {Dang} and J. {Yin} and B. {Wang} and W. {Zheng}},
  journal={Tsinghua Science and Technology}, 
  title={Deep learning based 2D human pose estimation: A survey}, 
  year={2019},
  volume={24},
  number={6},
  pages={663-676},
  doi={10.26599/TST.2018.9010100}
}

@article {leap-animal-pose,
	author = {Pereira, T. and Aldarondo, D. and Willmore, L. and Kislin, M. and Wang, S.S. and Murthy, M. and Shaevitz, J. W.},
	title = {Fast animal pose estimation using deep neural networks},
	elocation-id = {331181},
	year = {2018},
	doi = {10.1101/331181},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Recent work quantifying postural dynamics has attempted to define the repertoire of behaviors performed by an animal. However, a major drawback to these techniques has been their reliance on dimensionality reduction of images which destroys information about which parts of the body are used in each behavior. To address this issue, we introduce a deep learning-based method for pose estimation, LEAP (LEAP Estimates Animal Pose). LEAP automatically predicts the positions of animal body parts using a deep convolutional neural network with as little as 10 frames of labeled data for training. This framework consists of a graphical interface for interactive labeling of body parts and software for training the network and fast prediction on new data (1 hr to train, 185 Hz predictions). We validate LEAP using videos of freely behaving fruit flies (Drosophila melanogaster) and track 32 distinct points on the body to fully describe the pose of the head, body, wings, and legs with an error rate of \&lt;3\% of the animal{\textquoteright}s body length. We recapitulate a number of reported findings on insect gait dynamics and show LEAP{\textquoteright}s applicability as the first step in unsupervised behavioral classification. Finally, we extend the method to more challenging imaging situations (pairs of flies moving on a mesh-like background) and movies from freely moving mice (Mus musculus) where we track the full conformation of the head, body, and limbs.},
	URL = {https://www.biorxiv.org/content/early/2018/05/25/331181},
	eprint = {https://www.biorxiv.org/content/early/2018/05/25/331181.full.pdf},
	journal = {bioRxiv}
}

@article{graving2019deepposekit,
  title={DeepPoseKit, a software toolkit for fast and robust animal pose estimation using deep learning},
  author={Graving, Jacob M and Chae, Daniel and Naik, Hemal and Li, Liang and Koger, Benjamin and Costelloe, Blair R and Couzin, Iain D},
  journal={eLife},
  volume={8},
  pages={e47994},
  year={2019},
  publisher={eLife Sciences Publications Limited},
  url={https://doi.org/10.7554/eLife.47994},
}

@inproceedings{densenet,
  author={G. {Huang} and Z. {Liu} and L. {Van Der Maaten} and K. Q. {Weinberger}},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Densely Connected Convolutional Networks}, 
  year={2017},
  volume={},
  number={},
  pages={2261-2269},
  doi={10.1109/CVPR.2017.243}}

@INPROCEEDINGS{mobilenetv2,
  author={M. {Sandler} and A. {Howard} and M. {Zhu} and A. {Zhmoginov} and L. {Chen}},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={MobileNetV2: Inverted Residuals and Linear Bottlenecks}, 
  year={2018},
  volume={},
  number={},
  pages={4510-4520},
  doi={10.1109/CVPR.2018.00474}}

@InProceedings{DenseposeEvo20,
  title={Transferring Dense Pose to Proximal Animal Classes},
  author={Artsiom Sanakoyeu and Vasil Khalidov and Maureen S. McCarthy
          and Andrea Vedaldi and Natalia Neverova},
  booktitle={CVPR},
  year={2020},
}

@inproceedings{thewlis-unsup-sphere,
 author = {Thewlis, James and Bilen, Hakan and Vedaldi, Andrea},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised learning of object frames by dense equivariant image labelling},
 url = {https://proceedings.neurips.cc/paper/2017/file/cbcb58ac2e496207586df2854b17995f-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{kanazawa2016warpnet,
  title={Warpnet: Weakly supervised matching for single-view reconstruction},
  author={Kanazawa, Angjoo and Jacobs, David W and Chandraker, Manmohan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3253--3261},
  year={2016}
}

@article{siftflow,
  added-at = {2018-11-14T00:00:00.000+0100},
  author = {Liu, Ce and Yuen, Jenny and Torralba, Antonio},
  biburl = {https://www.bibsonomy.org/bibtex/28c58580daa657ed11da2c37b9b4c3969/dblp},
  ee = {https://www.wikidata.org/entity/Q46713520},
  interhash = {2b0da35b9daf9d24d02ea6199e259d6d},
  intrahash = {8c58580daa657ed11da2c37b9b4c3969},
  journal = pami,
  keywords = {dblp},
  number = 5,
  pages = {978-994},
  timestamp = {2018-11-15T15:01:23.000+0100},
  title = {SIFT Flow: Dense Correspondence across Scenes and Its Applications.},
  url = {http://dblp.uni-trier.de/db/journals/pami/pami33.html#LiuYT11},
  volume = 33,
  year = 2011
}

@inproceedings{unsup-articulated-objects,
  title     = "Unsupervised Learning of Object Landmarks through Conditional Image Generation", 
  author    = "Tomas Jakab and Ankush Gupta and Hakan Bilen and Andrea Vedaldi",  
  year      = "2018",  
  language  = "English",  
  pages     = "1--12",  
  booktitle = nips,  
  note      = "Thirty-second Conference on Neural Information Processing Systems, NIPS 2018 ; Conference date: 03-12-2018 Through 08-12-2018",  
  url       = "https://nips.cc/", }

@InProceedings{flowweb-efros,
author = {Zhou, Tinghui and Jae Lee, Yong and Yu, Stella X. and Efros, Alyosha A.},
title = {FlowWeb: Joint Image Set Alignment by Weaving Consistent, Pixel-Wise Correspondences},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{Bristow2015DenseSC,
  title={Dense Semantic Correspondence Where Every Pixel is a Classifier},
  author={H. Bristow and Jack Valmadre and S. Lucey},
  journal={2015 IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={4024-4031}
}

@Comment{jabref-meta: databaseType:bibtex;}
