% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
\begin{abstract}
    Across many sectors concerned with animal husbandry, there is a growing need for automated tools for continuously monitoring captive animals. In farmyards, zoos, veterinary centres, animal research facilities and many others, humans are typically responsible for identifying signs of disease or distress within their animal populations. While this can be effective, a significant challenge is posed when a small number of humans are expected to care for large animal groups.
    
    Existing automated systems often install cameras and use computer vision algorithms to track motion and/or predict behaviours. However, these approaches are either low fidelity or cannot be readily applied to identifying ill health due to ethical concerns around data collection. This thesis proposes a solution based on using 3D morphable models (3DMMs) as a useful intermediary 3D animal representation, enabling identification of adverse events and reducing the task-specific data requirements for downstream behaviour/welfare prediction tasks. A 3DMM is a specially designed mesh, supplied with parameters that constrain deformations. Typical reconstruction pipelines tackle reconstructing a 3D articulated structure as estimating the 3DMM parameters per input frame. 
    
    This thesis focuses on designing methods for 3D animal reconstruction, making use of suitable 3DMMs. We as humans are highly proficient at estimating the 3D structure of articulated subjects, such as animals or people. Even from a single image or video sequence, a human can with reasonable accuracy, predict the 3D locations of the animal's limbs, estimate body proportions and even the camera's location and viewing direction. However, these remain challenging tasks for computers. 

    Recently, great progress has been made in 3D \emph{human} reconstruction but there are particular challenges with prevent naively transferring these techniques to animal categories. Firstly, human reconstruction techniques use large, specialized datasets of images with corresponding 2D and 3D annotations to learn accurate 3DMMs and train neural networks. Unfortunately, animal datasets are extremely limited which has led to significant prior work in animals requiring per-frame manual annotations at test time. This lack of data also contributes to difficulties in designing detailed 3D priors, which are needed to cover the enormous pose and shape diversity among animal species when compared to humans. Other challenges faced in this thesis are common to humans and animals alike, such as when tackling ambiguous input imagery, for example caused by self or environmental occlusions. 

    This thesis proposes a series of methods which are designed to tackle these challenges. \Cref{chap:cgas} begins with the first approach to perform fully \emph{automatic} 3D reconstruction for a wide range of quadruped species, based on a graphics pipeline for generating synthetic data. \Cref{chap:wldo} introduces WLDO, an automatic and \emph{real-time} system for 3D dog reconstruction. This chapter covers an approach for improving the representational power of a low-fidelity 3DMM; a common problem for animals, since the lack of 3D training data necessitates learning from other sources, such as artist-designed figurines. The approach operates without a real 3D dataset and produces state-of-the-art accuracy on a challenging new dataset StanfordExtra, outperforming energy minimization approaches even when they are given ground truth test time annotations. \Cref{chap:3dmulti} proposes a technique for reconstructing images with heavy occlusion, which is an open problem across 3D reconstruction literature and a common failure mode of existing systems. The approach achieves state-of-the-art performance on challenging benchmarks.
    
    % an open problem across 3D reconstruction literature, for both animals and humans,   common for animals due to limited 3D training data, based on learning from a large 2D dataset  and au approach that generates synthetic data from a graphics pipeline to perform the first \emph{automatic} 3D reconstruction of a variety of animal categories. 
    
    % necessitating methods explored in this thesis based on weakly or self-supervTechniques in humans benefit from techniques in humans benefit hugely from large image datasets with corresponding 3D and 2D annotations which are used in the design of 3DMMs and in loss functions for machine learning algoriths. Unfortunately, animal datasets are extremely limited  necessitating . Shape and pose diversity.
    
    
    % which necessitates the self-supervised approach based on synthetic data in \Cref{chap:cgas} and weakly-supervised approach in \Cref{chap:wldo}. The latter chapter also proposes improvements to existing 3DMMs for animals, which are neceesarily built from artist data rather than real-world scans. 
    
    % A well designed 3DMM is thought to be suitably expressive to support clinical diagnoses, and should significantly reduce or eliminate the need for training data for behaviours or other welfare indicators. 

    % tackles the challenge current 3DMMs for animals, built from artist data rather than real-world scans, are of low detail. These issues are compounded for animals, where the pose and shape variation is much more complex and diverse. , as are the modes of ambiguity in natural scenes. \Cref{chap:wldo} explores a mechanism for Specific work is tackled in this thesis to examine 3D reconstruction in cases of images with significant occlusion.  
    
    % Although this may naviely appear to be Many of the techniques take inspiration from similar methods in 3D human reconstruction, although it should be jnotedWhile much related work towards designing methods for modelling animals with 3D morphable models and predictig automatic recovery of a If such a model can be automatically recovered from an input image or video, Employing such a model is intended as a step towards , which can be automatically recovered from an input image or video and is suitably expressive to support diagnoses and reduces (or eliminates) task-specific training data.

    % This work particularly inspired by recent work in 3D human reconstruction which rely on \emph{3D morphable models} such as the Skinned Multi-Person Linear model to act as a useful proxy representation for the subject. 

    % Humans are highly proficient at inferring the 3D structure of articulated objects. Even from a single image or video, humans can predicting the 3D locations of the animal's limbs, estimate body proportions and even the camera's location and viewing direction. However, these remain chalenging tasks for computers. 
    
    % The majority of existing work targets the special case of 3D human reconstruction. Techniques have popularized the use of \emph{3D morphable models} (3DMMs), a kind of parameterized 3D mesh designed to act as strong prior knowledge over the shape and pose of the target species. However, these techniques cannot be directly translated to reconstructing general animal categories. 
    
    
    % animals 
    
    % parameterized 3D meshes In order to overcome inherent ambiguities associated with reconstructing 3D objects from 2D input, as popularized in human reconstruction, it is useful to make use of strong priors over the object category.
    
    % Despite great progress in this category, 
    
    % such tasks are still challenging for computers. a human can predict the 3D locations of the limbs, estimate the animal's body propoto . In particular, from an input example, given an humans can predict reasona humans can predict reasonably accurately the position of the limbs, estimate However, this is still a challenging task for computers. In part due to promising commercial applications, most work in this category targets 3D \emph{human} reconstruction as a special case, and takes advantage of large image datasets with associated 3D and 2D annotations. Unfortunately, available data is much more limited for animal subjects, necessitating novel methods to handle has targeted Most work targets 3D \emph{human} reconstruction Inspired by recent work in human reconstruction, this thesis proposes methods for the automatic 3D reconstruction of animal subjects from images and video. Although humans are highly proficient at inferring the 3D shape and pose of articulated objects, even from a single view, this is still challenging for computers.  
    
    % treat this as a behaviour recognition task, in which an input video is processed by a machine learning algorithm to output a set of predefined behaviours. 
    
    % machine learning classification task, a video sequence is processed This thesis focuses on reconstructing 3D animals from monocular images or video. 
    
    % Across many sectors concerned with animal husbandry, there is a growing need for automated tools for continuously monitoring captive animals. Existing systems tackle this by training machine learning algorithsm to recognise predefined behaviours on a live video. This thesis proposes that a useful 
    
    % there is growing interest in automated tools which  interest in designing automated tools which can assist for a system able to continuously monitor captive animals. 
  
    % This report discusses the development of a system to track, monitor and react to signs of poor physiological and psychological health among captive animals. In this work, it is proposed that a useful component of such a system would be the recovery of a detailed per-frame 3D animal reconstruction from an input video sequence. This is achieved through an approach which combines discriminative machine learning with generative model fitting to recover strong shape and pose attributes. 
    
    % We present a system to recover the 3D shape and motion of a wide variety of quadrupeds from video. The system comprises a machine learning front-end which predicts candidate 2D joint positions, a discrete optimization which finds kinematically plausible joint correspondences, and an energy minimization stage which fits a detailed 3D model to the image. In order to overcome the limited availability of motion capture training data from animals, and the difficulty of generating realistic synthetic training images, the system is designed to work on silhouette data. The joint candidate predictor is trained on synthetically generated silhouette images, and at test time, deep learning methods or standard video segmentation tools are used to extract silhouettes from real data. The system is tested on animal videos from several species, and shows accurate reconstructions of 3D shape and pose.
\end{abstract}
