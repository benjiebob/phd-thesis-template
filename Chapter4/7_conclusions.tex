\section{Conclusions}
The chapter introduces a technique for reconstructing 3D quadrupeds from video by using a quadruped model parameterized in shape and pose. By incorporating automatic segmentation tools, the pipeline can be deployed without requiring human intervention or even precise knowledge of the species of animal being considered. The method performs well on examples encountered in the real world, generalizes to unseen animal species and is robust to challenging shapes and poses. 

As a direction for future work, it would be worthwhile to look at methods for synthetic image generation that preserve important edge information lost during silhouette extraction. In particular, the lost interior contours cause ambiguities which necessitate the OJA method described here. An alternative is to extend the recent work of SMALST~\lazycite{SMALST}{SMALST} (which requires hand-clicked training images) by instead synthetizing realistic textures using generative adverserial networks. Of course, it is important to ensure the texture generation process preserves the sampled pose parameters. A naive method is to rendering texture as a UV map on top of the SMAL model, but this could also be framed as an image-to-image translation problem, beginning with a low detail SMAL render and mapping to a photorealistic image with a carefully designed pose-preserving generator. Other components of the system which could be improved would be building a more sophisticated motion prior, able to represent likely animal trajectories. In addition, robustness to environmental factors as shown in \Cref{fig:blooper} could be improved by rendering synthetic causes of occlusion (perhaps even as rectangles). 
    