%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Conclusions}\label{chap:summary}

\ifpdf
    \graphicspath{{Chapter7/Figs/Raster/}{Chapter7/Figs/PDF/}{Chapter7/Figs/}}
\else
    \graphicspath{{Chapter7/Figs/Vector/}{Chapter7/Figs/}}
\fi

\section{Summary and discussion}

This thesis has discussed the topic of dense 3D animal reconstruction from monocular images and video, using 3D morphable models as a strong prior over the object category. To this end, \Cref{chap:relwork} has covered the necessary technical background and related work, focusing particularly on the design of articulated models and methods for fitting them to input data. The core technical chapters have focused on three important considerations of particular importance to 3D animal tracking. 

\Cref{chap:cgas} contributes to perhaps the two most pertinant questions when reconstructing animals, namely (a) how to deal with the lack of 3D training data and (b) how to avoid the need for user intervention. The strategy for overcoming this involves using a 3D animal graphics model to generate training data for a deep learning pipeline. Consideration is given to various mechanisms for bridging the so-called `synth-to-real domain gap', but settles with a key observation that silhouettes are extremely informative to animal shape and pose and are simple to synthesize. In addition, silhouettes have become simple to extract from test set RGB sequences, by harnessing large training datasets generally designed for instance segmentation tasks. However, the chapter acknowledges that ambiguities exist when working in the silhouette domain, and proposes an optimal joint assignment discrete optimization problem, solved using quadratic programming and optimized using genetic algorithms, to try and recover the most likely skeleton trajectory over a video sequence. As is shown experimentally, the recovered trajectories are sufficient as input to a model fitting pipeline, which optimizes the SMAL~\cite{xxx} 3D morphable model to match this input evidence. 

However, despite success on these sequences, the approach has certain downsides. As demonstrated in \Cref{chap:wldo}, the quality of predicted joints at test time is heavily dependent on the quality of the shape and pose prior for generating varied shapes. This results in suboptimal performance on uncontrolled ``in-the-wild'' datasets of challenging shapes and poses, such as varied dog images sourced on the internet which are outside the range of the prior. Further, the approach is too slow to process video in real-time, which inhibits applications which could otherwise report behaviour anomalies in animals. These issues are tackled with the WLDO approach in \Cref{chap:wldo}. Firstly, a new 3D morphable model is designed with new limb scaling parameters and a more representative 3D shape prior is learnt during the training loop of a neural network. The method operates in real-time, and shows state-of-the-art performance on StanfordExtra, a new challenging dataset introduced in this chapter with no energy minimization phase necessary. The lack of 3D training data is overcome by means of a weakly supervised training strategy, making use of 2D annotations present in the training dataset.

Although WLDO is somewhat capable of handling images with some occlusion, similar to state-of-the-art approaches designed for 3D human reconstruction, heavily ambiguous input images cause failures. As explored, even when these networks are fine-tuned with such examples, they are restricted to recovering only a single possible reconstruction obtained by `averaging' over the space of plausible reconstructions. \Cref{chap:3dmulti} explores this problem and proposes to output a set of plausible reconstructions consistent with the input. Ambiguities in humans and animals are represented again using 3D morphable models. A multi-hypothesis network is trained using a best-of-$M$ loss. The chapter overcomes theoretical limitations with this construction, proposing a quantizer weighted by a normalizing flow prior to allow optimal sets of different sizes to be recovered without the need to entirely retrain the network. In additon, a 2D reprojection loss is used to discourage mode degeneration and ensure consistency to the input evidence. This approach is the first to specifically model ambiguities in an animal category and also achieves state of the art performance on competitive human benchmarks. Importantly, results are also demonstrated on RGBD-Dog, the first publically-available animal dataset with 3D annotations available for training and evaluation.

\section{Applicability to industrial animal tracking}

Many of the tools and techniques presented in this thesis have already found applications in industries strongly connected to animal husbandry. In particular, leading healthcare companies have made use of these technologies as part of their commitment to the 3Rs principles which apply when conducting pre-clinical trials of candidate medications that involve animals. Integrating continuous and automated animal monitoring systems to these studies helps \emph{R}efine the quality of collected data, which leads to an overall \emph{R}eduction to the number of animals required for each trial to produce results of scientific significance. This project, and others like it, also support the development of computerised behavioural models which could one day \emph{R}eplace the use of animals altogether.

For reasons of data privacy and confidentiality, results and images for this projects cannot be released in this thesis. However, permisison has been granted to allow a discussion of the methodology including some implementation details. 

A priority development area involves the WLDO system, presented in \Cref{chap:wldo} of this thesis. However, the system as demonstrated is restricted to producing 3D reconstructions of only a single animal. In addition, there has so far been no attention given to important downstream tasks, which are required by animal experts to enable prediction of animal behaviours and identities. This section will cover adaptations made to WLDO that enable its use in multi-housed animal environments, and a discussion on how to obtain per-animal behavioural output from 3D morphable model parameters.

%  The basis of research for this project has therefore been to extend WLDO to operate on multi-housed animals and to implement the downstream task, which outputs behaviours and identities. These components are handled in the subsequent sections:

 \subsection{Extending WLDO to multi-animal tracking}
 
 For reasons of animal welfare, it is preferable that animals in captivity should be housed in groups rather than in isolation~\cite{xxx}. To achieve this, it is necessary to adapt WLDO to support tracking and 3D reconstruction of multiple animals simultaneously. Inspired by recent work in object detection, WLDO has been implemented on top of an existing RCNN architecture. The components here are mostly standard: an input image is processed by a region proposal network (RPN) and region of interest (ROI) aligner to pass bounding object features to the later prediction heads. The WLDO layers which output 3D morphable model parameters are implemented as a new head, alongside existing heads which produce animal class ID (e.g. dog, cat etc.) and bounding box coordinates. Weights for existing layers (e.g. backbone and existing heads) are initialized using the MaskRCNN network trained on the MSCOCO dataset. This has the effect of making the core architecture proficient at identifying certain animal cateogries (i.e. up to the prediction heads) are initialized during the MaskRCNN network, pretrained on MSCOCO. This has the efficient that the core architecture is already proficient at detecting animal bounding boxes and identifying the species type at the start of training. Weights for the entire network (including those for the WLDO prediction head) are optimized by training on an internal dataset which have manually annotated segmentations and keypoints. With this architecture, the multi-animal WLDO network is capable at producing 3D reconstructions for all detected animals in the scene.

 \subsection{Predicting behaviours and identities}
 
 To meet the needs of veterninary experts, it is important to track individual animal behaviours throughout pre-clinical trials. Achieving this aim is hoped to contribute to a package of existing processes used to reveal insights around efficacy and potential risks associated with candidate medications. However, for reasons of ethics, it is discouraged to use physical markers on animals due to the risk of increased stress so the system should not rely on these for identification. Finally, the system should work continuously and therefore must operate on grayscale night vision images.

 The identity prediction is implemented as an additional prediction RCNN head which outputs an identity ID. For this reason, at present it is necessary to fine tune the weights of this branch for different animal subjects. Work is in progress to replace this module with an embedding space, learnt from multiple subjects, which can be used to discriminate between identities with only a few examples. The behaviour prediction module is implemented as a linear layer, mapping the parameters for the 3D morphable model to behaviour labels. This works effectively with only a fairly small network since all background information,texture and camera variation have already been solved for. 

 The modules are trained on a dataset collected internally over two days from 8 HD cameras with infrared night vision support. Labelling was conducted by in-house veterinary and clinical experts. Training the full system takes approximately 24 hours on a single V100 GPU.

% PICTURE

\section{Discussions and areas for future work}

This final section of this thesis discusses the emerging field of 3D animal reconstruction as a whole with a view towards worthwhile avenues for further research.

\subsection{Representations of articulated 3D structures}

This thesis has used a popular category of 3D morphable models based on triangular meshes rigged with internal skeleton. Triangle meshes are a popular choice for representating 3D surfaces and particularly for articulated structures, as methods can take advantage of established deformation constraints such as linear blend skinning. In addition, compared to alternatives (e.g. voxel grids, OctNets, point clouds etc.) the representation is compact and easy to render. Mesh vertices (and linear combinations of them) are also useful constructs in order to determine correspondences between the 3D model and other modalities, particularly images. Minimizing the distance between projected mesh locations and image keypoints is an important loss used frequently in this thesis. 

However, the use of triangle meshes as 3D morphable models have some limitations, particularly when modelling detailed 3D surfaces or representing a large class of animal species.

\subsubsection{Implicit surface representations}

Although coarse animal shapes are easily represented~\cite{} uising a mesh structure, high frequency surface details (e.g. facial details, fur etc.) can only be captured with a large number of triangles and vertices. This necessitates an extremely complex mesh which becomes difficult for optimizers to fit, incurs a large memory footprint and slows down training and inference.

As discussed in \Cref{ss:implicit}, Neural Radience Fields (NeRF) are a relatively new class of implicit functions which are particularly adept at compactly representing high frequency details in complex 3D scenes. Starting with novel view synthesis on static scenes, there has been considerable progress in existing the formulation to video, generalizing to new environments, and most related to this thesis, operating on deformable 3D objects. 

At the time of writing, successful examples have been demonstrated on full humans and some body part categories (e.g. hands) but not yet for animal subjects. Part of the reason for this is likely the lack of large-scale 3D animal datasets which are typically required (but not always~\cite{xxx}) for training. 

% https://arxiv.org/pdf/2104.03953.pdf SNARF, ANerf
% Animatable Neural Radiance Fields for Human Body Modeling

While some NeRF approaches~\lazycite{}{NPMs, Multi-view NHR} learn human articulation from large-scale pose datasets (e.g. AMASS [30], DeformingThings4D [26], CAPE [30], MANO [45]), some maintain an internal 3D skeleton structure and focus NeRF at modelling complex skin/clothing features relative to these landmarks~\lazycite{xxx}{SNARF, ANerf, Animatable Neural Radience Fields}. Such an strategy could form the basis for an approach for animals, perhaps using WLDO in~\Cref{chap:wldo} to obtain a 3D animal skeletons and camera parameters and using an implicit representation to model the skin details. An interesting research direction here is to test if the implicit representation could be supervised by silhouettes alone.

If achieved, such a representation could enable facial features, skin abrasions, fur and other complex features to be incoporated. If recovered in images and video sequences of real animals, these details could be of considerable therapeutic significance. However, for real-world applications, consideration should be taken to ensure fast rendering at inference time. Until recently~\cite{xxx}, this has been a commonly cited concern with neural representations, which have typically required slow processes such as marching cubes. In addition, care must be taken when planning to use neural representations in a pipeline with a later downstream task, e.g. behaviour prediction. It is not immediately clear how to pass features from such a representation to subsequent classifiers; of course, one could pass network weights as input but these may be too complex or noisy a learning signal for effective behaviour prediction. However, animal shape could be modelled with sufficient precision, such a feature vector could be discriminative enough to use directly for animal identity -- potentially enabling single-shot recognition of different animals in multi-housed (or even wildlife~\lazycite{camera trap}{} scenarios.)

% implicit methods and incurs a large memory footprint that slows training and inference. 

% However, there are a recent class of implicit methods have been shown to be particularly adept at compactly representing high frequency details. As briefly discussed in ~\Cref{chap:relwork}, the idea is to represent the surface \emph{as} a neural network. For example, consider a network $f: \R{3} \mapsto \mathbb{B}$ which maps 3D locations to a binary occupancy value. The network outputs $1$ for 3D locations within the mesh and $0$ otherwise. Even higher quality results can be obtained by incorporating camera viewing direction into the input vector and outputing RGB values on top of occupany; with such a formulation, complex appearance details such as lighting and reflectance can be captured. 

% The class of Neural Radience Fields (NeRF) have produced impressive results on static scenes and have recently been extended to video~\cite{} and deformable categories. A common recent approach for modelling humans is to start by predicting a 3D skeleton (e.g. using SPIN~\cite{}) and allowing the implict function to represent the skin relative to the joints. However, these approaches require full 3D supervision of watertight meshes and have yet to show strong results on challenging input images.

% At present, implicit functions have not yet been applied to modelling animal categories, perhaps due to the increased challenge in capturing the full range of pose and shape diversity. However, research in this direction may lead to models being able to fully capture details such as fur, skin abrasions and other factors potentailly of therapeutic significance. 

% although attempts to model articulated objects  them to modelling objects with articulation is restricted to relatively simple cases. For example, the PIFu uses an implicit representation of humans and even captures clothing, but requires full 3D training data for training and results are shown only on humans captured in simple environments, poses and camera viewing directions. 

% works only in simple cases. However, while implicit functions are adept at representing static scenes, they struggle without these kind of implicit functions are non-structured, and are without an internal skeleton, therefore they struggle to model articulation. Further, these approaches typically require large 3D datasets of watertight meshes for training. 

% There are some recent works which aim to represent articulated 3D structures with implicit functions. A popular approach is to first predict an internal skeleton and use the implicit function to represent the ``skin''. This seems a promising approach; reducing the need for large datasets to learn pose and instead focusing the network on it's primary job to capture surface details.
% Neural Parametric Models for 3D Deformable Shapes

% Rendering is also slow... but say there has been work on this.

% However, despite representing being adept at representing the coarse structure of an animal, meshes are inefficient when needing to represent high frequency surface features, particularly when such features are unknown in advance. For large scale scenes, meshes are a poor choice due to the need to  

% Two problems; (1) you need lots of triangles to represent details, (2) you can't distribute triangles as needed. 

% Complain about the fidelity of reconstruction, difficultly representing fine-grained features. 

% Introduce implicit representations. Then complain they are useless at articulated strucutres. It's of course possible to try and learn a deformation space from examples, but such work is dififcult and relies on a large dataset of examples.
% We need articulated Nerf which contains an internal skeleton.

\subsubsection{Modelling the animal kingdom}

% Introduce automatic rigging, and structured shape representations which can gain and lose features. 

The technical chapters of this thesis have covered methods for reconstructing 3D humans, dogs, camels, tigers, cats and many more. However, apart from humans as a special case, despite being of diverse shapes the remaining animals have similar topology. For instance, they have similar skeletal structures with precisely four legs and a tail. A natural question is to ask whether the approaches defined in this thesis would extend to different, stranger animal classes. For example, would WLDO work on an octupus? The hesitant answer to this is `yes' subject to having access to a representative 3D morphable model that matches the topology of the target species. With sufficient training examples, the initialized model should adapt using expectation maximization steps to better capture the species in question. However, given that there are 8.7 million different species of animal on Earth, it is clearly intractable to consider designing a 3D morphable model, complete with an internal skeleton and shape space for all of them.

This concern can be handled in two ways. The first avenue of exploration is to look at techniques which do not require a 3D morphable model at all. As mentioned before, there are implicit approaches for simpler poses~\lazycite{PIFu}{} which require full 3D training data and emerging approaches based requiring only 2D keypoints, for simpler animals such as birds (although strong initialization is still used)~\lazycite{}{Bird paper} and human keypoints~\cite{}{David's papers}. However, the quality and robustness of such techniques on in-the-wild and uncontrolled images are not yet comparable. However, these are worthy avenues of research.

Alternatively, one could consider what would be required to design a more sophisticated 3D morphable model that generalizes to all conceivable species. Clearly, a large dataset of 3D scans covering a decent range of species would be needed; but one could imagine sourcing these from existing artist models, biomechanical scans, museums etc. Of interest then, is how to design a model that generalizes to all species?

Recent work in shape interpolation, modelling etc. 


% idesigning a more sophisticated morphable model which extends to all species. much more representative shape prior by training on the plethora of 3D artist data or even obtaining scans from museums. 

% unconare still far behind  and attempts to template-free approaches for humans in simpler capture environments, attempts at extending non-rigid structure from motion methodologies for humans this for humans~\cite{PiFu}, static objects There have been early attempts at this,  For this reason, it is proposed that a worthy area of investigation is to design 

% fall into a category of ``medium-to-large quadruped'' thesis, attention has been given to reconstruction 

% and OctTrees and as-rigid-as-possible come with a long history of as they are compact and easy to render. ParticulaSpecifically for articulated structures, techniques benefit from established deformation constraints such as linear blend skinning to ensure plausible surface variations. 


% In this thesis, meshes have been integrated into neural network architectures by fixing the triangulation according to a 3D morphable model and outputting vertex locations parameterized by shape and pose. 


% are a suitable choice for modelling articulated structures, as reconstruction techniques can make use of established deformation constraints, such as  including linear blend skinning, as-rigid-as-possible deformation constraints, differentiable rendering and others. Additionally,  for this work, due to a long history of work in 


% However, it is not clear how to design a 3D morphable model to cover groups of animals with considerably different topologies. an appropriate does not naturally extend when representing animals with considerably different topologies; for example, consider modelling an octupus, dog and marmoset. In such a case, it is necessary 

% In addition, methods can take advantage of a long history of methods for meshes, many covered in \Cref{chap:relwork} of this thesis including differentiable rendering, linear blend skining, ARAP regularizers and many more etc. 

% For representing articulated structures, meshes are more appropriate than voxel grids, in which a surface is represented as occupany values over a fixed sized 3D grid. For this reason, the resolution of the output surface scales cubicly in the size of the grid, most of which is usually sparse. Improvements to this have recently been made with OctNets~\cite{xxx}, which use octrees~\cite{xxx} to learn a more efficient partitioning of the voxel space, thereby reducing memory. 

% However, 

% neural   and are an appropriate choice for neural networks; sinceoffering a fixed set of vertices a 3D surface a representation has some benefits; for example, the such a representation has some limitations. triangular meshes rigged with internals as the 
% representation for  

% \begin{enumerate}
%     \item Use of radiance fields. PiFu and Nerf. etc.
%     \item Represented thousands of different animals. Shape modelling from structured chairs interpolation paper.
% \end{enumerate}


\subsection{Representations of reconstruction ambiguity}

Foo.

% Normalizing flows 
% Shape modelling (difficult with SMPL, easier with implicits)
% Enable training sets and calibrated confidences for animal exports

\subsection{Creation and collection of large-scale animal datasets.}

\begin{enumerate}
    \item Using GANs to generate synthetic data. Perhaps discuss project explored so far.
    \item Collecting real world animal datasets.
\end{enumerate}


\subsection{Improved use of video for motion priors and force analysis}

\begin{enumerate}
    \item Force analysis, temporal modelling
    \item Multi-view allows better shape reconstruction
\end{enumerate}




% \section{Broader impact}

% Our method improves the ability of machines to understand human body poses in images and videos.
% Understanding people automatically may arguably be misused by bad actors.
% However, importantly, our method is \emph{not} a form of biometric as it does \emph{not} allow the identification of people.
% Rather, only their overall body shape and pose is reconstructed, but these details are insufficient for unique identification.
% In particular, individual facial features are not reconstructed at all.

% Furthermore, our method is an improvement of existing capabilities, but does not introduce a radical new capability in machine learning.
% Thus our contribution is unlikely to facilitate misuse of technology which is already available to anyone.

% Finally, any potential negative use of a technology should be balanced against positive uses.
% Understanding body poses has many legitimate applications in VR and AR, medical, assistance to the elderly, assistance to the visual impaired, autonomous driving, human-machine interactions, image and video categorization, platform integrity, etc.



