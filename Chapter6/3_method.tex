\section{Method}\label{s:method}

% \subsection{Predicting multiple hypotheses.}

The method starts with a neural network architecture that implements the function $G(I) = (\theta, \beta, \posn, f)$ described above.
For quadrupedal animals, the WLDO network introduced in ~\Cref{chap:wldo} is used. For humans, as shown in SPIN \cite{kolotouros19learning}, the HMR \cite{kanazawa18end-to-end} architecture attains state-of-the-art results for this task.
However, the regressors $G(I)$ for both networks given an input image $I$, can only produce a single unique solution.
In general, and in particular for cases with a high degree of reconstruction ambiguity, this chapter focuses on predicting a \emph{set} of plausible 3D poses rather than a single one.
%
Therefore, the model is extended to explicitly produce a set of $M$ different hypotheses $G_m (I) = (\pose_m, \shape_m, \posn_m, f_m)$, $m=1,\dots,M$.
This is easily achieved by modifying the final output layer of both networks to produce a tensor $M$ times larger, effectively stacking the hypotheses.
In what follows, the learning scheme that drives the monocular predictor $G$ to achieve an optimal coverage of the plausible poses consistent with the input image. The approach is summarized in~\cref{fig:arch_diagram}. 

\subsection{Learning with multiple hypotheses}

For learning the model, access is assumed to a training set of $N$ images $\{I_i\}_{i =1,\dots,N}$, each cropped around a subject (either an animal or human).
Furthermore, for each training image $I_i$, it is assumed that the following are known: (1) the 2D location $Y_i$ of the body joints (2) their 3D location $Y_i$, and (3) the ground truth SMPL fit $(\theta_i, \beta_i, \gamma_i)$.
Depending on the set up, some of these quantities can be inferred from the others (e.g.~the selector $\jointselect$ can be used to convert ground truth 3D morphable model parameters to the 3D joints $Y_i$ and then the camera projection to obtain $X_i$).
In the sequel, the following notation is used to express the 3D joint positions of the model predicted by the network's $m$-th SMAL/SMPL predictor $G_m (I) = (\pose_m, \shape_m, \posn_m, f_m)$ applied to image $I_{i}$:

\begin{equation}
  \hat Y^{m}(I_{i}) = \posn_{m} * v(\pose_{m},\shape_{m})\jointselect
\end{equation}

And the following notation represents 3D joint predictions projected into the 2D image plane:

\begin{equation}
  \hat X^{m}(I_{i})) = \proj_{f_{m}}(\posn_{m} * v(\pose_{m},\shape_{m})\jointselect)
\end{equation}
  

\subsection{Best-of-$M$ loss.}
Given a single input image, the network predicts a set of poses, where at least one should be similar to the ground truth 3D annotation $\inputjtsthree_{i}$.
This is captured by the best-of-$M$ loss~\cite{guzman2012multiple}:

\begin{equation}\label{e:loss-best}
  \mathcal{L}_\text{best}(\jointselect,G;m^*)
  =
  \frac{1}{N}
  \sum_{i=1}^N
  \big \| \inputjtsthree_{i}- \hat Y^{m_i^*}(I_i) \big \|,
  ~~
  m_i^*
  =
  \operatornamewithlimits{argmin}_{m=1,\dots,M}
  \big \| \inputjtsthree_{i} -  \hat Y^{m}(I_i) \big \|,
\end{equation}

%$\hat X^{m}(I_i) = J(G_m(V(I_i)))$ are the 3D joints estimated by the $m$-th SMAL/SMPL predictor $G_m(I_i)$ applied to image $I_i$.
In this way, only the best hypothesis is steered to match the ground truth, leaving the other hypotheses free to sample the space of ambiguous solutions.
During the computation of this loss, we also extract the best index $m^*_i$ for each training example.

\subsection{Limitations of best-of-$M$.}

As noted in~\cref{s:intro}, best-of-$M$ only guarantees that one of the $M$ hypotheses is a good solution, but says nothing about the other ones.
Furthermore, in applications it is often useful to modulating the number of hypotheses generated, but the best-of-$M$ regressor $G(I)$ only produces a fixed number of output hypothesis $M$, and changing $M$ would require retraining from scratch, which is intractable.
% , in the sense that $G$ does not straightforwardly allow for outputting a different number of $n \neq M$ hypotheses.
% If a different number of hypotheses $M$ is desired, the na\:{\i}ve solution entails the intractably costly process of re-training $G$ for each possible value of $M$.
% If one wanted to output a different number of hypotheses, the na\"ive approach would entail the intractably costly process of re-training $G$ for each possible value of $M$.

These issues are addressed by introducing a method trains a best-of-$M$ model for a large $M$ \emph{once} which can be leveraged later to generate an arbitrary number of $n < M$ hypotheses without the need of retraining, while ensuring that these are good representatives of likely body poses.

\subsection{$n$-quantized-best-of-$M$}
Formally, given a set of $M$ predictions
$\mathcal{\hat Y}^M(I) = \{\hat Y^1(I), ..., \hat Y^M(I)\}$ the goal is to generate a smaller $n$-sized set
$\mathcal{\bar Y}^n(I) = \{\bar Y^1(I), ..., \bar Y^n(I)\}$ which preserves the information contained in $\mathcal{\hat Y}^M$.
In other words, $\mathcal{\bar Y}^n$ \emph{optimally quantizes} $\mathcal{\hat Y}^M$.
% To this end, inspired by the quantization literature \cite{gray1998quantization}, we define the best-of-$M$ quantization energy $E$ as:
% \begin{equation}\label{e:loss-quant}
% E(\mathcal{\hat X} | \mathcal{\bar X}) = \mathbb{E}_{p(\mathcal{\bar X})}
% \left[
%     \min_{\{\bar X^1, ... \bar X^n\}} \| \hat X^i - \bar X^j \|^2
% \right],
% \end{equation}
%
% \paragraph{$n$-quantized-best-of-$M$}
To this end, the output of the best-of-$M$ model can be interpreted as a set of choices $\mathcal{\hat Y}^M(I)$ for the possible pose.
These poses are of course not all equally likely, but it is difficult to infer their probability from~\eqref{e:loss-best}.
Instead, the following approximation is used.
A prior $p(Y)$ is designed that expresses the likelihood of possible poses (defined in the next section), and set:
\begin{equation}\label{e:conditional}
p(Y|I)
=
p(Y|\mathcal{\hat Y}^M(I))
=
\sum_{i=1}^{M}
\delta({Y} - \hat{Y}^i(I))
\frac{p(\hat{Y}^i(I))}{
\sum_{k=1}^{M} p(\hat{Y}^k(I))}
\end{equation}
This can be interpreted as using the best-of-$M$ output as a conditioning \emph{set} (i.e.~an unweighted selection of plausible poses) and then use the prior $p(Y)$ to weight the samples in this set.
With the weighted samples, $K$-means \cite{lloyd1982least} further quantizes the best-of-$M$ output while minimizing the quantization energy $E$:
\begin{equation}\label{e:loss-quant}
E(\mathcal{\bar Y} | \mathcal{\hat Y}) = \mathbb{E}_{p(Y|I)}
\left[
    \min_{\{\bar Y^1, ..., \bar Y^n\}} \| Y - \bar Y^j \|^2
\right]
=
\sum_{i=1}^{M}
\frac{p(\hat{Y}^i(I))}{
\sum_{k=1}^{M} p(\hat{Y}^k(I))}
\min_{\{\bar Y^1,\dots,\bar Y^n\}}
\| \hat Y^i(I) - \bar Y^j \|^2
\end{equation}
This can be done efficiently on GPU --- in fact, for this problem K-Means consumes less than 20\% of the execution time of the entire forward pass of the network. 
% \rk{TODO: add in the Mean0 strategy to technical details.}

% Notice that, apart from the data vectors $\hat X$ and the quants $\bar X$, the quantization energy also assumes knowledge the probability density $p(\mathcal{\hat X})$ over the space of 3D skeletons $\mathcal{\hat X}$. \rk{justify that using prior $p(\mathcal{X})$ over the restricted set $\mathcal{\bar X}$ is in fact $p(\mathcal{X}|I)$}

\subsection{Learning the pose prior with normalizing flows.}
% In order to obtain $p(X)$, we propose to learn a deep generative model.
% While recent advances in generative modelling brought various possibilities (VAE \cite{}, GANs \cite{}), we opt for deep normalizing flows \cite{} due their intriguing property of being able to exactly maximize the data log likelihood.
In order to obtain $p(Y)$, a normalizing flow model is proposed in the form of the RealNVP network $f$ described in \cref{s:preliminaries} and the supplementary. RealNVP optimizes the log likelihood $\mathcal{L}_\text{nf}(f)$ of training ground truth 3D skeletons $\{Y_1, ... Y_N\}$ annotated in their corresponding images $\{I_1, ..., I_N\}$ :
\begin{equation}\label{e:loglik}
\mathcal{L}_\text{nf}(f)
=
-
\frac{1}{N}
\sum_{i=1}^N
\log p(Y_i)
=\\
-
\frac{1}{N}
\sum_{i=1}^N
\left(
\log \mathcal{N}(f(Y_i))
-
\sum_{l=1}^L
\log
\left|
\frac{d f_l(Y_{li})}{d Y_{li}}
\right|
\right).
\end{equation}

\subsection{2D re-projection loss.}

Since the best-of-$M$ loss optimizes a single prediction at a time, often some members of the ensemble $\mathcal{\hat Y}(I)$ drift away from the manifold of plausible human body shapes, ultimately becoming `dead' predictions that are never selected as the best hypothesis $m^*$.
In order to prevent this, a 2D re-projection loss acts across all hypotheses for a given image.
More specifically, the set of predicted 3D reconstructions are constrained to lie on projection rays passing through the 2D input keypoints with the following \emph{hypothesis re-projection loss}:
\begin{equation}\label{e:loss-ri}
  \mathcal{L}_\text{ri}(\jointselect,G)
  =
  \frac{1}{N}
  \sum_{i=1}^N
  \sum_{m=1}^M
  % \big \| X^*_i - \proj_{f}(\hat Y^m(I)) \big \|.
  \big \| X^*_i - \hat X^m(I_i) \big \|.
\end{equation}

Note that many training images exhibit significant occlusion, so $X^*$ often contains invisible or missing points. This is handled by masking $\mathcal{L}_\text{ri}$ to prevent these points contributing to the loss.

\paragraph{SMAL/SMPL loss.}
The final loss terms, introduced by prior work~\cite{kanazawa18end-to-end,pavlakos18learning,kolotouros19learning}, penalize
deviations between the predicted and ground truth 3D model parameters.
For this method, these are only applied to the best hypothesis $m_i^*$ found above:
% {\small
% \begin{align}\label{e:smpl}
% \mathcal{L}_\theta(G;m^*) =& \frac{1}{N}
%   \sum_{i=1}^N \| \theta_i - G_{\theta,m_i^*}(I_i)\| \\
% \mathcal{L}_\beta(G;m^*) =& \frac{1}{N} \label{e:smpl2}
%   \sum_{i=1}^N \| \beta_i - G_{\beta,m_i^*}(I_i)\| \\
% \mathcal{L}_V(G;m^*) =& \frac{1}{N} \label{e:smpl3}
%   \sum_{i=1}^N \| S(\theta_i,\beta_i,\gamma_i) - S(G_{(\theta,\beta,\gamma),m_i^*}(I_i))\| \\
% \mathcal{L}_\text{rb}(G;m^*) =& \frac{1}{N} \label{e:smpl4}
%   \sum_{i=1}^N \| \hat Y_i - \pi(s_{i}, t_{i})(\hat{X}^{m_i^*}(I_i))\|
% \end{align}
% }
{\small
\begin{align}
\mathcal{L}_\theta(G;m^*) = \frac{1}{N}
  \sum_{i=1}^N \| \theta_i - G_{\theta,m_i^*}(I_i)\| \\
\mathcal{L}_V(G;m^*) = \frac{1}{N} \label{e:smpl}
  \sum_{i=1}^N \| \posn_i * v(\pose_i, \shape_i) - G_{\posn,m_i^*}(I_i)*v(G_{(\pose,\shape),m_i^*}(I_i))\| \\
\mathcal{L}_\beta(G;m^*) = \frac{1}{N}
  \sum_{i=1}^N \| \beta_i - G_{\beta,m_i^*}(I_i)\|; \\
\mathcal{L}_\text{rb}(G;m^*) = \frac{1}{N} \label{e:smpl2}
  % \sum_{i=1}^N \| X^*_i - \proj_{f}(\hat{Y}^{m_i^*}(I_i))\|
  \sum_{i=1}^N \| X^*_i - \hat{X}^{m_i^*}(I_i)\|
\end{align}}%
Note here that $\mathcal{L}_\text{rb}$ is used to refer to a 2D re-projection error between the best hypothesis and ground truth 2D points $X^*_i$. This differs from the earlier loss $\mathcal{L}_\text{ri}$, which is applied across all modes to enforce consistency to the visible \emph{input} points. Note that it would have been possible to use \cref{e:smpl,e:smpl2} to select the best hypothesis $m_i^*$, but it would entail an unmanageable memory footprint due to the requirement of SMPL-meshing for every hypothesis before the best-of-$M$ selection. 

% TODO: Explain the mini-SMPL optimization.
\subsection{Mini SMAL/SMPL optimization}

TODO - explain this.

\subsection{Overall loss.}

The model is thus trained to minimize:
\begin{equation}\label{e:loss-total}
%   \begin{aligned}
%     \mathcal{L}(J,G)&=
%     \lambda_\text{nf} \mathcal{L}_\text{nf}(J,G) +
%     \lambda_\text{ri} \mathcal{L}_\text{ri}(J,G) \\& +
%     \lambda_\text{best} \mathcal{L}_\text{best}(J,G;m^*) +
%     \lambda_\theta \mathcal{L}_\theta(J,G;m^*) \\& +
%     \lambda_\beta \mathcal{L}_\beta(J,G;m^*) +
%     \lambda_\text{V} \mathcal{L}_V(J,G;m^*) \\& +
%     \lambda_\text{rb} \mathcal{L}_\text{rb}(J,G;m^*)
%   \end{aligned}
  \begin{aligned}
    \mathcal{L}(\jointselect,G)&=
    \lambda_\text{ri} \mathcal{L}_\text{ri}(\jointselect,G) +
    \lambda_\text{best} \mathcal{L}_\text{best}(\jointselect,G;m^*) +
    \lambda_\theta \mathcal{L}_\theta(\jointselect,G;m^*) \\& +
    \lambda_\beta \mathcal{L}_\beta(\jointselect,G;m^*) +
    \lambda_\text{V} \mathcal{L}_V(\jointselect,G;m^*) +
    \lambda_\text{rb} \mathcal{L}_\text{rb}(\jointselect,G;m^*)
  \end{aligned}
\end{equation}
where $m^*$ is given in~\cref{e:loss-best} and
$
\lambda_\text{ri},
\lambda_\text{best},
\lambda_\theta,
\lambda_\beta,
\lambda_\text{V},
\lambda_\text{rb}
$
are weighing factors.
A consistent set of loss weights are used across all experiments
$\lambda_\text{best}= 25.0, \lambda_\theta=1.0,
\lambda_\beta=0.001,
\lambda_\text{V}=1.0,
$ and set $\lambda_\text{ri} = 1.0$.
%
Since the training of the normalizing flow $f$ is independent of the rest of the model, $f$ is trained separately by optimizing $\mathcal{L}_\text{nf}$ with the weight of $\lambda_\text{nf}=1.0$. Samples from the trained normalizing flows are shown in \Cref{fig:nf_samples}.

\input{Chapter6/FigTex/fig-flowsamples.tex}